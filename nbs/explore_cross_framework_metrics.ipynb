{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import enum\n",
    "import random\n",
    "from types import ModuleType\n",
    "from typing import Any, Protocol, Tuple, Union, runtime_checkable\n",
    "\n",
    "import cupy as cp\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.utils.dlpack\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_SAMPLES = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducibility\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "cp.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# typical data types for preds and target\n",
    "preds_list = [random.random() for _ in range(NUM_SAMPLES)]\n",
    "target_list = [random.randint(0, 1) for _ in range(NUM_SAMPLES)]\n",
    "\n",
    "preds_tuple = tuple([random.random() for _ in range(NUM_SAMPLES)])\n",
    "target_tuple = tuple([random.randint(0, 1) for _ in range(NUM_SAMPLES)])\n",
    "\n",
    "preds_np = np.random.rand(NUM_SAMPLES)\n",
    "target_np = np.random.randint(0, 2, NUM_SAMPLES)\n",
    "\n",
    "preds_pd = pd.Series(np.random.rand(NUM_SAMPLES))\n",
    "target_pd = pd.Series(np.random.randint(0, 2, NUM_SAMPLES))\n",
    "\n",
    "preds_cp = cp.random.rand(NUM_SAMPLES)\n",
    "target_cp = cp.random.randint(0, 2, NUM_SAMPLES)\n",
    "\n",
    "preds_torch = torch.rand(NUM_SAMPLES, device=\"cuda\")\n",
    "target_torch = torch.randint(0, 2, (NUM_SAMPLES,), device=\"cuda\")\n",
    "\n",
    "eval_test_data = [\n",
    "    # (preds_list, target_list),\n",
    "    # (preds_tuple, target_tuple),\n",
    "    (preds_np, target_np),\n",
    "    # (preds_pd, target_pd),\n",
    "    (preds_cp, target_cp),\n",
    "    (preds_torch, target_torch),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see: https://dmlc.github.io/dlpack/latest/\n",
    "# and: https://data-apis.org/array-api/latest/design_topics/copies_views_and_mutation.html\n",
    "\n",
    "# define a type that has __dlpack__ and __dlpack_device__ methods\n",
    "_PyCapsule = Any\n",
    "\n",
    "\n",
    "@runtime_checkable\n",
    "class DLPackTensor(Protocol):\n",
    "    def __dlpack__(self) -> _PyCapsule:\n",
    "        ...\n",
    "\n",
    "    def __dlpack_device__(self) -> Any:\n",
    "        ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_torch_tensor(\n",
    "    arg: Union[ArrayLike, DLPackTensor], copy: bool = False\n",
    ") -> torch.Tensor:\n",
    "    # should only support:\n",
    "    # object types: list, tuple, numpy array, DLPack-compatible arrays/tensors\n",
    "    # data types: bool, signed/unsigned integers, float and complex dtypes\n",
    "    # signed/unsigned integers, float and complex dtypes\n",
    "    if isinstance(arg, torch.Tensor):\n",
    "        return arg\n",
    "\n",
    "    if isinstance(arg, DLPackTensor):\n",
    "        torch_tensor = torch.utils.dlpack.from_dlpack(arg)\n",
    "    else:\n",
    "        try:\n",
    "            torch_tensor = torch.tensor(arg)\n",
    "        except:\n",
    "            raise\n",
    "\n",
    "    if copy:\n",
    "        torch_tensor = torch_tensor.clone()\n",
    "\n",
    "    return torch_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUPPORTED_DLDEVICE_GPUS = [\"kDLGPU\", \"kDLROCM\"]\n",
    "\n",
    "\n",
    "class DLDeviceType(enum.IntEnum):\n",
    "    \"\"\"DLDeviceType enum from DLPack specification.\"\"\"\n",
    "\n",
    "    kDLCPU = (1,)  # CPU device\n",
    "    kDLGPU = (2,)  # CUDA GPU device\n",
    "    kDLCUDAHost = (3,)  # Pinned CUDA CPU memory by cudaMallocHost\n",
    "    kDLOpenCL = (4,)  # OpenCL devices.\n",
    "    kDLVulkan = (7,)  # Vulkan buffer for next generation graphics.\n",
    "    kDLMetal = (8,)  # Metal for Apple GPU\n",
    "    kDLVPI = (9,)  # Verilog simulator buffer\n",
    "    kDLROCM = (10,)  # ROCm GPUs for AMD GPUs\n",
    "    kDLROCMHost = (11,)  # Pinned ROCm CPU memory allocated by hipMallocHost\n",
    "    kDLExtDev = (12,)  # Reserved extension device type\n",
    "\n",
    "\n",
    "def _get_dl_device_type(arr: Any) -> DLDeviceType:\n",
    "    \"\"\"Get the DLDeviceType of the given (dlpack-compatible) array.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arr : Any\n",
    "        The (dlpack-compatible) array to get the DLDeviceType of.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    DLDeviceType\n",
    "        The DLDeviceType of the array.\n",
    "\n",
    "    Raises\n",
    "    ------\n",
    "    TypeError\n",
    "        If the array does not have a `__dlpack_device__` attribute.\n",
    "\n",
    "    \"\"\"\n",
    "    if not hasattr(arr, \"__dlpack_device__\"):\n",
    "        raise TypeError(\n",
    "            \"Expected `arr` to have a `__dlpack_device__` attribute. \"\n",
    "            \"Got {}.\".format(type(arr))\n",
    "        )\n",
    "\n",
    "    device = arr.__dlpack_device__()\n",
    "    return DLDeviceType(device[0])\n",
    "\n",
    "\n",
    "def get_array_module(*args: Any) -> ModuleType:\n",
    "    \"\"\"Choose the array module based on the input arguments.\n",
    "\n",
    "    If at least one of the arguments is on the GPU (CUDA or ROCM), the `cupy`\n",
    "    module will be returned.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    args : Any\n",
    "        Objects for which to determine the array module.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    The array module - `cupy`, if the object is on the GPU, otherwise `numpy`.\n",
    "\n",
    "    \"\"\"\n",
    "    for arg in args:\n",
    "        if all(hasattr(arg, attr) for attr in [\"__dlpack__\"]):\n",
    "            device_type = _get_dl_device_type(arg)\n",
    "            if device_type.name in SUPPORTED_DLDEVICE_GPUS:\n",
    "                return cp\n",
    "\n",
    "    return cp.get_array_module(*args)\n",
    "\n",
    "\n",
    "def to_xpy(*arrays: Any) -> Tuple[Any]:\n",
    "    \"\"\"Convert array/tensor-like objects to either cupy or numpy arrays.\n",
    "\n",
    "    If multiple objects are passed, they must all be on the same device.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    arrays : Any\n",
    "        Objects to convert to cupy or numpy arrays.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    out : tuple\n",
    "        Tuple of cupy and/or numpy arrays.\n",
    "\n",
    "    \"\"\"\n",
    "    xp = get_array_module(*arrays)\n",
    "    is_np = xp == np\n",
    "    out = []\n",
    "\n",
    "    for array in arrays:\n",
    "        if hasattr(array, \"__dlpack__\"):\n",
    "            device_type = _get_dl_device_type(array)\n",
    "            if (not is_np and device_type.name not in SUPPORTED_DLDEVICE_GPUS) or (\n",
    "                is_np and device_type.name in SUPPORTED_DLDEVICE_GPUS\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    f\"Expected to convert `arrays` to {xp.__name__} arrays. \"\n",
    "                    f\"Got array object on {device_type.name} device. Please \"\n",
    "                    \"move all arrays to the same device before calling this function.\"\n",
    "                )\n",
    "\n",
    "            xp_arr = xp._from_dlpack(array) if is_np else xp.from_dlpack(array)\n",
    "        else:\n",
    "            try:\n",
    "                xp_arr = xp.asarray(array)\n",
    "            except:  # noqa: E722\n",
    "                raise TypeError(\n",
    "                    \"Expected `arrays` to contain be of one of the following types: \"\n",
    "                    \"Sequence | numpy.ndarray | cupy.ndarray | torch.Tensor. \"\n",
    "                    \"Got {}.\".format(type(array))\n",
    "                )\n",
    "        out.append(xp_arr)\n",
    "\n",
    "    return tuple(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tests for the utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data: python scalars, lists, tuples, numpy arrays, pandas series, cupy arrays and torch tensors\n",
    "# data types: int, float, bool, str\n",
    "test_data: list[Any] = [\n",
    "    # python scalars\n",
    "    1,\n",
    "    1.0,\n",
    "    \"1\",\n",
    "    False,\n",
    "    # python lists\n",
    "    [1, 2, 3],\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [\"1\", \"2\", \"3\"],\n",
    "    [False, True, False],\n",
    "    # python tuples\n",
    "    (1, 2, 3),\n",
    "    (1.0, 2.0, 3.0),\n",
    "    (\"1\", \"2\", \"3\"),\n",
    "    (False, True, False),\n",
    "    # numpy arrays\n",
    "    np.array([1, 2, 3]),\n",
    "    np.array([1.0, 2.0, 3.0]),\n",
    "    np.array([\"1\", \"2\", \"3\"]),\n",
    "    np.array([[True, False], [False, True]]),\n",
    "    np.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]),\n",
    "    # pandas series\n",
    "    pd.Series([1, 2, 3]),\n",
    "    pd.Series([1.0, 2.0, 3.0]),\n",
    "    pd.Series([\"1\", \"2\", \"3\"]),\n",
    "    pd.Series([True, False, True]),\n",
    "    # cupy arrays\n",
    "    cp.array([1, 2, 3]),\n",
    "    cp.array([1.0, 2.0, 3.0]),\n",
    "    # cp.array([\"1\", \"2\", \"3\"]), # cupy does not support string arrays\n",
    "    # cp.array([[True, False], [False, True]]), # dlpack only supports numeric types\n",
    "    cp.array([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]),\n",
    "    # torch tensors - cpu\n",
    "    torch.tensor([1, 2, 3]),\n",
    "    torch.tensor([[True, False], [False, True]]),\n",
    "    torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]),\n",
    "    # torch tensors - gpu\n",
    "    torch.tensor([1, 2, 3], device=\"cuda\"),\n",
    "    torch.tensor([[True, False], [False, True]], device=\"cuda\"),\n",
    "    torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]], device=\"cuda\"),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in test_data:\n",
    "    print(f\"Input: {data} ({type(data)})\")\n",
    "    try:\n",
    "        print(f\"Output: {convert_to_torch_tensor(data)}\")\n",
    "    except Exception as err:\n",
    "        print(err)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #1: Array API standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import array_api_compat as apc\n",
    "\n",
    "\n",
    "def stat_scores_array_api(preds, target):\n",
    "    xp = apc.get_namespace(preds, target)\n",
    "\n",
    "    if preds.dtype in (\n",
    "        xp.float32,\n",
    "        xp.float64,\n",
    "    ):  # NOTE: float16 and bfloat16 are not supported\n",
    "        if not xp.all((preds >= 0) * (preds <= 1)):\n",
    "            # preds is logits, convert with sigmoid\n",
    "            preds = preds.sigmoid()\n",
    "        preds = preds > 0.5\n",
    "\n",
    "    preds = preds.reshape(preds.shape[0], -1)\n",
    "    target = target.reshape(target.shape[0], -1)\n",
    "\n",
    "    tp = ((target == preds) & (target == 1)).sum().squeeze()\n",
    "    fn = ((target != preds) & (target == 1)).sum().squeeze()\n",
    "    fp = ((target != preds) & (target == 0)).sum().squeeze()\n",
    "    tn = ((target == preds) & (target == 0)).sum().squeeze()\n",
    "\n",
    "    scores = xp.stack([tp, fp, tn, fn, tp + fn], 0).squeeze()\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_api_results = []\n",
    "for pred, target in eval_test_data:\n",
    "    result = stat_scores_array_api(pred, target)\n",
    "    array_api_results.append(result)\n",
    "\n",
    "print(array_api_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #2: DLPack + numpy/cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_scores_xp(preds, target):\n",
    "    preds, target = to_xpy(preds, target)\n",
    "    xp = get_array_module(preds, target)\n",
    "\n",
    "    if preds.dtype in (\n",
    "        xp.float32,\n",
    "        xp.float64,\n",
    "    ):  # NOTE: float16 and bfloat16 are not supported\n",
    "        if not xp.all((preds >= 0) * (preds <= 1)):\n",
    "            # preds is logits, convert with sigmoid\n",
    "            preds = preds.sigmoid()\n",
    "        preds = preds > 0.5\n",
    "\n",
    "    preds = preds.reshape(preds.shape[0], -1)\n",
    "    target = target.reshape(target.shape[0], -1)\n",
    "\n",
    "    tp = ((target == preds) & (target == 1)).sum().squeeze()\n",
    "    fn = ((target != preds) & (target == 1)).sum().squeeze()\n",
    "    fp = ((target != preds) & (target == 0)).sum().squeeze()\n",
    "    tn = ((target == preds) & (target == 0)).sum().squeeze()\n",
    "\n",
    "    scores = xp.stack([tp, fp, tn, fn, tp + fn], 0).squeeze()\n",
    "\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xp_results = []\n",
    "for pred, target in eval_test_data:\n",
    "    result = stat_scores_xp(pred, target)\n",
    "    xp_results.append(result)\n",
    "\n",
    "print(xp_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option #3 DLPack + Torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute metrics for different data types\n",
    "# check that the inputs are not mutated\n",
    "from torchmetrics.functional.classification import stat_scores\n",
    "from copy import deepcopy\n",
    "\n",
    "tm_results = []\n",
    "for pred, target in eval_test_data:\n",
    "    pred_copy = deepcopy(pred)\n",
    "    target_copy = deepcopy(target)\n",
    "\n",
    "    preds_tensor = convert_to_torch_tensor(pred)\n",
    "    target_tensor = convert_to_torch_tensor(target)\n",
    "\n",
    "    result = stat_scores(preds_tensor, target_tensor, task=\"binary\")\n",
    "    tm_results.append(to_xpy(result))\n",
    "\n",
    "    # check that the values of preds and target are not mutated\n",
    "    assert torch.equal(preds_tensor, convert_to_torch_tensor(pred_copy))\n",
    "    assert torch.equal(target_tensor, convert_to_torch_tensor(target_copy))\n",
    "\n",
    "print(tm_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cyclops",
   "language": "python",
   "name": "cyclops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
