





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>cyclops.evaluate.metrics.functional.precision_recall &mdash; cyclops  documentation</title>
      <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/css/cyclops.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/copybutton.css" type="text/css" />
    <link rel="shortcut icon" href="../../../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/clipboard.min.js"></script>
        <script src="../../../../../_static/copybutton.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
<script type="text/javascript">
  window.onload = function() {
    document.body.innerHTML = document.body.innerHTML.replace(/ module/g, '');
    document.body.innerHTML = document.body.innerHTML.replace(/ package/g, '');
  }
</script>

</head>

<body class="wy-body-for-nav">
  <!--
    Lie about what theme we really are when some RTD-injected JS fetches the
    full versions panel from the RTD API.  RTD's JS replaces the stub versions
    panel in the Sphinx-generated HTML with the full versions panel it fetches
    from the RTD API.  If the API thinks we're not sphinx_rtd_theme, it will
    serve us the wrong HTML and the panel will float as a "badge" when it
    shouldn't.  As a customized version of sphinx_rtd_theme, we really do want
    the same HTML it gets.  See also the diagnoses in
    <https://github.com/nextstrain/docs.nextstrain.org/issues/76>.

    This bit of JS finds the data RTD injects into the page and modifies it
    before the code that RTD injects runs and looks at the data.  RTD's
    <script>s (in <head>) run before this JS, but they wait until the DOM is
    ready to actually do any work.  This gives us a chance to modify the data
    during DOM load before the RTD code actually uses it.

      -trs, 27 Jan 2022
  -->
  <script>
    (() => {
      try {
        console.log("Lying about the theme to RTD's JS so the versions panel works properly. üôà");

        /* Update global variable, which is used in the request to get the RTD
         * "footer" that includes the versions panel.
         */
        if (window.READTHEDOCS_DATA)
          window.READTHEDOCS_DATA.theme = "sphinx_rtd_theme";

        /* Update stored JSON in case anything else deserializes it later.
         * Comments in the RTD-injected HTML source claim the global variable
         * above is deprecated.
         */
        var script = document.querySelector("#READTHEDOCS_DATA");
        if (script)
          script.innerHTML = JSON.stringify({ ...JSON.parse(script.innerHTML), theme: "sphinx_rtd_theme" });
      }
      catch (err) {
        console.log("Lying about the theme to RTD's JS failed‚Ä¶ oh well. ü§∑", err);
      }
    })();
  </script>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #efeeed" >




  <a href="https://vectorinstitute.github.io/cyclops/">
    <img src="../../../../../_static/cyclops_logo-dark.png" class="logo" alt="Logo"/>
  </a>



  <div class="subproject">
    <a href="../../../../../index.html" class="project-name" alt="Documentation Home">
      cyclops
    </a>

    
    
    

  </div>




<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html">üê£ Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html#developing">üßëüèø‚Äçüíª Developing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html#documentation">üìö Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html#notebooks">üìì Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html#citation">üéì Citation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../contributing.html">Contributing to cyclops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../tutorials.html">Tutorials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #efeeed" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">cyclops</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  

  
  
    <li><a href="https://vectorinstitute.github.io/cyclops/">Home</a></li>
    <li><a href="../../../../../index.html">cyclops</a></li>
  

  
  
    <li><a href="../../../../index.html">Module code</a></li>
  

  

      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for cyclops.evaluate.metrics.functional.precision_recall</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Functions for computing precision and recall scores on different input types.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span><span class="p">,</span> <span class="n">cast</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">numpy.typing</span> <span class="k">as</span> <span class="nn">npt</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics._classification</span> <span class="kn">import</span> <span class="n">_prf_divide</span>

<span class="kn">from</span> <span class="nn">cyclops.evaluate.metrics.functional.stat_scores</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_binary_stat_scores_args_check</span><span class="p">,</span>
    <span class="n">_binary_stat_scores_format</span><span class="p">,</span>
    <span class="n">_binary_stat_scores_update</span><span class="p">,</span>
    <span class="n">_multiclass_stat_scores_format</span><span class="p">,</span>
    <span class="n">_multiclass_stat_scores_update</span><span class="p">,</span>
    <span class="n">_multilabel_stat_scores_format</span><span class="p">,</span>
    <span class="n">_multilabel_stat_scores_update</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">cyclops.evaluate.metrics.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_average_arg</span><span class="p">,</span>
    <span class="n">_get_value_if_singleton_array</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">_precision_recall_reduce</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">tp</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">int_</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">int_</span><span class="p">],</span>
    <span class="n">fp</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">int_</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">int_</span><span class="p">],</span>
    <span class="n">fn</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">int_</span><span class="p">],</span> <span class="n">np</span><span class="o">.</span><span class="n">int_</span><span class="p">],</span>
    <span class="n">metric</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span> <span class="s2">&quot;recall&quot;</span><span class="p">],</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float_</span><span class="p">],</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute precision or recall scores and apply specified average.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tp : numpy.ndarray</span>
<span class="sd">        True positives.</span>
<span class="sd">    fp : numpy.ndarray</span>
<span class="sd">        False positives.</span>
<span class="sd">    fn : numpy.ndarray</span>
<span class="sd">        False negatives.</span>
<span class="sd">    metric : Literal[&quot;precision&quot;, &quot;recall&quot;]</span>
<span class="sd">        Metric to compute.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None]</span>
<span class="sd">        Average to apply. If None, return scores for each class.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1]</span>
<span class="sd">        Value to return when there are no true positives or true negatives.</span>
<span class="sd">        If set to &quot;warn&quot;, this acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    scores : numpy.ndarray or float</span>
<span class="sd">        Precision or recall scores. If ``average`` is None, return scores for</span>
<span class="sd">        each class as a numpy.ndarray. Otherwise, return the average as a</span>
<span class="sd">        float.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">numerator</span> <span class="o">=</span> <span class="n">tp</span>
    <span class="n">different_metric</span> <span class="o">=</span> <span class="n">fp</span> <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;precision&quot;</span> <span class="k">else</span> <span class="n">fn</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="n">numerator</span> <span class="o">+</span> <span class="n">different_metric</span>

    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;micro&quot;</span><span class="p">:</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">numerator</span><span class="p">))</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">denominator</span><span class="p">))</span>

    <span class="n">modifier</span> <span class="o">=</span> <span class="s2">&quot;predicted&quot;</span> <span class="k">if</span> <span class="n">metric</span> <span class="o">==</span> <span class="s2">&quot;precision&quot;</span> <span class="k">else</span> <span class="s2">&quot;true&quot;</span>

    <span class="n">score</span> <span class="o">=</span> <span class="n">_prf_divide</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">numerator</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">numerator</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">numerator</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">denominator</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span> <span class="k">if</span> <span class="n">denominator</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">denominator</span><span class="p">,</span>
        <span class="n">metric</span><span class="p">,</span>
        <span class="n">modifier</span><span class="p">,</span>
        <span class="n">average</span><span class="p">,</span>
        <span class="n">warn_for</span><span class="o">=</span><span class="n">metric</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;weighted&quot;</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">zero_division</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">]:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">average</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">score</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_get_value_if_singleton_array</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>  <span class="c1"># type: ignore[assignment]</span>

    <span class="k">return</span> <span class="n">result</span>


<div class="viewcode-block" id="binary_precision"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.precision_recall.binary_precision.html#cyclops.evaluate.metrics.functional.precision_recall.binary_precision">[docs]</a><span class="k">def</span> <span class="nf">binary_precision</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute precision score for binary classification.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : npt.ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : npt.ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    pos_label : int, default=1</span>
<span class="sd">        The label of the positive class.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for deciding the positive class.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Precision score.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import binary_precision</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0, 1, 1, 1]</span>
<span class="sd">    &gt;&gt;&gt; binary_precision(target, preds)</span>
<span class="sd">    0.6666666666666666</span>
<span class="sd">    &gt;&gt;&gt; target = [[0, 1, 0, 1], [0, 0, 1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.1, 0.9, 0.8, 0.2], [0.2, 0.3, 0.6, 0.1]]</span>
<span class="sd">    &gt;&gt;&gt; binary_precision(target, preds)</span>
<span class="sd">    0.6666666666666666</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_binary_stat_scores_args_check</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">)</span>

    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_binary_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_binary_stat_scores_update</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">)</span>

    <span class="n">precision_score</span> <span class="o">=</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">precision_score</span><span class="p">)</span></div>


<div class="viewcode-block" id="multiclass_precision"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.precision_recall.multiclass_precision.html#cyclops.evaluate.metrics.functional.precision_recall.multiclass_precision">[docs]</a><span class="k">def</span> <span class="nf">multiclass_precision</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float_</span><span class="p">],</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute precision score for multiclass classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : npt.ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : npt.ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    num_classes : int</span>
<span class="sd">        Number of classes in the dataset.</span>
<span class="sd">    top_k : int, optional</span>
<span class="sd">        If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">        be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">        set to 1.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the precision score for each class. Otherwise,</span>
<span class="sd">        use one of the following options to compute the average precision score:</span>

<span class="sd">        - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">            positives and false positives.</span>
<span class="sd">        - ``macro``: Calculate metric for each class, and find their unweighted</span>
<span class="sd">            mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metric for each class, and find their average</span>
<span class="sd">            weighted by the support (the number of true instances for each class).</span>
<span class="sd">            This alters &quot;macro&quot; to account for class imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    precision : float or numpy.ndarray</span>
<span class="sd">        Precision score. If ``average`` is None, return a numpy.ndarray of</span>
<span class="sd">        precision scores for each class.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``average`` is not one of ``micro``, ``macro``, ``weighted``</span>
<span class="sd">        or ``None``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import multiclass_precision</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 2, 0]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0, 2, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; multiclass_precision(target, preds, num_classes=3)</span>
<span class="sd">    array([1., 0., 0.])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_average_arg</span><span class="p">(</span><span class="n">average</span><span class="p">)</span>

    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_multiclass_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_multiclass_stat_scores_update</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="multilabel_precision"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.precision_recall.multilabel_precision.html#cyclops.evaluate.metrics.functional.precision_recall.multilabel_precision">[docs]</a><span class="k">def</span> <span class="nf">multilabel_precision</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float_</span><span class="p">],</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute precision score for multilabel classification tasks.</span>

<span class="sd">    The input is expected to be an array-like of shape (N, L), where N is the</span>
<span class="sd">    number of samples and L is the number of labels. The input is expected to</span>
<span class="sd">    be a binary array-like, where 1 indicates the presence of a label and 0</span>
<span class="sd">    indicates its absence.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : npt.ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : npt.ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    num_labels : int</span>
<span class="sd">        Number of labels for the task.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for deciding the positive class.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the precision score for each label. Otherwise,</span>
<span class="sd">        use one of the following options to compute the average precision score:</span>

<span class="sd">        - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">            positives and false positives.</span>
<span class="sd">        - ``macro``: Calculate metric for each label, and find their unweighted</span>
<span class="sd">            mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metric for each label, and find their average</span>
<span class="sd">            weighted by the support (the number of true instances for each label).</span>
<span class="sd">            This alters &quot;macro&quot; to account for label imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    precision: float or numpy.ndarray</span>
<span class="sd">        Precision score. If ``average`` is None, return a numpy.ndarray of</span>
<span class="sd">        precision scores for each label.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If average is not one of ``micro``, ``macro``, ``weighted``,</span>
<span class="sd">        or ``None``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import multilabel_precision</span>
<span class="sd">    &gt;&gt;&gt; target = [[0, 1], [1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.1, 0.9], [0.2, 0.8]]</span>
<span class="sd">    &gt;&gt;&gt; multilabel_precision(target, preds, num_labels=2)</span>
<span class="sd">    array([0., 1. ])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_average_arg</span><span class="p">(</span><span class="n">average</span><span class="p">)</span>

    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_multilabel_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_multilabel_stat_scores_update</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="precision"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.precision_recall.precision.html#cyclops.evaluate.metrics.functional.precision_recall.precision">[docs]</a><span class="k">def</span> <span class="nf">precision</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">],</span>
    <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float_</span><span class="p">],</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute precision score for different classification tasks.</span>

<span class="sd">    Precision is the ratio of correctly predicted positive observations to the</span>
<span class="sd">    total predicted positive observations.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : npt.ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : npt.ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    task : Literal[&quot;binary&quot;, &quot;multiclass&quot;, &quot;multilabel&quot;]</span>
<span class="sd">        Task type.</span>
<span class="sd">    pos_label : int</span>
<span class="sd">        Label of the positive class. Only used for binary classification.</span>
<span class="sd">    num_classes : Optional[int]</span>
<span class="sd">        Number of classes. Only used for multiclass classification.</span>
<span class="sd">    threshold : float</span>
<span class="sd">        Threshold for positive class predictions. Default is 0.5.</span>
<span class="sd">    top_k : Optional[int]</span>
<span class="sd">        Number of highest probability or logits predictions to consider when</span>
<span class="sd">        computing multiclass or multilabel metrics. Default is None.</span>
<span class="sd">    num_labels : Optional[int]</span>
<span class="sd">        Number of labels. Only used for multilabel classification.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None]</span>
<span class="sd">        Average to apply. If None, return scores for each class. Default is</span>
<span class="sd">        None. One of:</span>

<span class="sd">        - ``micro``: Calculate metrics globally by counting the total true</span>
<span class="sd">            positives and and false positives.</span>
<span class="sd">        - ``macro``: Calculate metrics for each label/class, and find their</span>
<span class="sd">            unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metrics for each label, and find their</span>
<span class="sd">            average weighted by support (the number of true instances for</span>
<span class="sd">            each label). This alters ``macro`` to account for label imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1]</span>
<span class="sd">        Value to return when there are no true positives or true negatives.</span>
<span class="sd">        If set to ``warn``, this acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    precision_score : numpy.ndarray or float</span>
<span class="sd">        Precision score. If ``average`` is not None or task is ``binary``,</span>
<span class="sd">        return a float. Otherwise, return a numpy.ndarray of precision scores</span>
<span class="sd">        for each class/label.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If task is not one of ``binary``, ``multiclass`` or ``multilabel``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; # (binary)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import precision</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0.1, 0.9, 0.8, 0.3]</span>
<span class="sd">    &gt;&gt;&gt; precision(target, preds, task=&quot;binary&quot;)</span>
<span class="sd">    1.</span>

<span class="sd">    &gt;&gt;&gt; # (multiclass)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import precision</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 2, 0, 1, 2]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.1, 0.6, 0.3], [0.05, 0.95, 0], [0.1, 0.8, 0.1],</span>
<span class="sd">    ...         [0.5, 0.3, 0.2],  [0.2, 0.5, 0.3], [0.2, 0.2, 0.6]]</span>
<span class="sd">    &gt;&gt;&gt; precision(target, preds, task=&quot;multiclass&quot;, num_classes=3,</span>
<span class="sd">    ...     average=&quot;macro&quot;)</span>
<span class="sd">    0.8333333333333334</span>

<span class="sd">    &gt;&gt;&gt; # (multilabel)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import precision</span>
<span class="sd">    &gt;&gt;&gt; target = [[0, 1], [1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.1, 0.9], [0.2, 0.8]]</span>
<span class="sd">    &gt;&gt;&gt; precision(target, preds, task=&quot;multilabel&quot;, num_labels=2,</span>
<span class="sd">    ...     average=&quot;macro&quot;)</span>
<span class="sd">    0.5</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">binary_precision</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_classes</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;Number of classes must be specified for multiclass classification.&quot;</span>
        <span class="k">return</span> <span class="n">multiclass_precision</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;Number of labels must be specified for multilabel classification.&quot;</span>
        <span class="k">return</span> <span class="n">multilabel_precision</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Task &#39;</span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">&#39; not supported, expected &#39;binary&#39;, &#39;multiclass&#39; or &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;&#39;multilabel&#39;.&quot;</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="binary_recall"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.precision_recall.binary_recall.html#cyclops.evaluate.metrics.functional.precision_recall.binary_recall">[docs]</a><span class="k">def</span> <span class="nf">binary_recall</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute recall score for binary classification.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : npt.ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : npt.ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    pos_label : int, default=1</span>
<span class="sd">        Label of the positive class.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for deciding the positive class.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        Recall score.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import binary_recall</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0, 1, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; binary_recall(target, preds)</span>
<span class="sd">    0.5</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_binary_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_binary_stat_scores_update</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">)</span>

    <span class="n">recall_score</span> <span class="o">=</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">cast</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="n">recall_score</span><span class="p">)</span></div>


<div class="viewcode-block" id="multiclass_recall"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.precision_recall.multiclass_recall.html#cyclops.evaluate.metrics.functional.precision_recall.multiclass_recall">[docs]</a><span class="k">def</span> <span class="nf">multiclass_recall</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float_</span><span class="p">],</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute recall score for multiclass classification.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : npt.ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : npt.ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    num_classes : int</span>
<span class="sd">        Number of classes.</span>
<span class="sd">    top_k : Optional[int]</span>
<span class="sd">        If given, and predictions are probabilities/logits, the recall will</span>
<span class="sd">        be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">        set to 1.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None]</span>
<span class="sd">        Average to apply. If None, return scores for each class. Default is</span>
<span class="sd">        None. One of:</span>

<span class="sd">        - ``micro``: Calculate metrics globally by counting the total true</span>
<span class="sd">            positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metrics for each label, and find their unweighted</span>
<span class="sd">            mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metrics for each label, and find their</span>
<span class="sd">            average weighted by support (the number of true instances for each label).</span>
<span class="sd">            This alters &quot;macro&quot; to account for label imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1]</span>
<span class="sd">        Value to return when there are no true positives or true negatives.</span>
<span class="sd">        If set to ``warn``, this acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or numpy.ndarray</span>
<span class="sd">        Recall score. If ``average`` is None, return a numpy.ndarray of</span>
<span class="sd">        recall scores for each class.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``average`` is not one of ``micro``, ``macro``, ``weighted``</span>
<span class="sd">        or ``None``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import multiclass_recall</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 2, 0, 1, 2]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.4, 0.1, 0.5], [0.1, 0.8, 0.1], [0.2, 0.2, 0.6],</span>
<span class="sd">    ...     [0.5, 0.3, 0.2], [0.2, 0.5, 0.3], [0.2, 0.2, 0.6]]</span>
<span class="sd">    &gt;&gt;&gt; multiclass_recall(target, preds, num_classes=3, average=&quot;macro&quot;)</span>
<span class="sd">    0.8333333333333334</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_average_arg</span><span class="p">(</span><span class="n">average</span><span class="p">)</span>

    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_multiclass_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_multiclass_stat_scores_update</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_classes</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="multilabel_recall"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.precision_recall.multilabel_recall.html#cyclops.evaluate.metrics.functional.precision_recall.multilabel_recall">[docs]</a><span class="k">def</span> <span class="nf">multilabel_recall</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float_</span><span class="p">],</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute recall score for multilabel classification tasks.</span>

<span class="sd">    The input is expected to be an array-like of shape (N, L), where N is the</span>
<span class="sd">    number of samples and L is the number of labels. The input is expected to</span>
<span class="sd">    be a binary array-like, where 1 indicates the presence of a label and 0</span>
<span class="sd">    indicates its absence.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : npt.ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : npt.ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    num_labels : int</span>
<span class="sd">        Number of labels in the dataset.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for deciding the positive class.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the recall score for each class. Otherwise,</span>
<span class="sd">        use one of the following options to compute the average score:</span>

<span class="sd">        - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">            positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metric for each label, and find their</span>
<span class="sd">            unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metric for each label, and find their</span>
<span class="sd">            average weighted by the support (the number of true instances</span>
<span class="sd">            for each label). This alters &quot;macro&quot; to account for label imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or numpy.ndarray</span>
<span class="sd">        Recall score. If ``average`` is None, return a numpy.ndarray of</span>
<span class="sd">        recall scores for each label.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``average`` is not one of ``micro``, ``macro``, ``weighted``</span>
<span class="sd">        or ``None``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import multilabel_recall</span>
<span class="sd">    &gt;&gt;&gt; target = [1, 1, 2, 0, 2, 2]</span>
<span class="sd">    &gt;&gt;&gt; preds = [1, 2, 2, 0, 2, 0]</span>
<span class="sd">    &gt;&gt;&gt; multilabel_recall(target, preds, num_classes=3)</span>
<span class="sd">    array([1.        , 0.5       , 0.66666667])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_average_arg</span><span class="p">(</span><span class="n">average</span><span class="p">)</span>

    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_multilabel_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_multilabel_stat_scores_update</span><span class="p">(</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="recall"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.precision_recall.recall.html#cyclops.evaluate.metrics.functional.precision_recall.recall">[docs]</a><span class="k">def</span> <span class="nf">recall</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">npt</span><span class="o">.</span><span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">],</span>
    <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="n">npt</span><span class="o">.</span><span class="n">NDArray</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">float_</span><span class="p">],</span> <span class="nb">float</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;Compute recall score for different classification tasks.</span>

<span class="sd">    Recall is the ratio tp / (tp + fn) where tp is the number of true positives</span>
<span class="sd">    and fn the number of false negatives. The recall is intuitively the ability</span>
<span class="sd">    of the classifier to find all the positive samples.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : npt.ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : npt.ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    task : Literal[&quot;binary&quot;, &quot;multiclass&quot;, &quot;multilabel&quot;]</span>
<span class="sd">        Task type.</span>
<span class="sd">    pos_label : int</span>
<span class="sd">        Label of the positive class. Only used for binary classification.</span>
<span class="sd">    num_classes : Optional[int]</span>
<span class="sd">        Number of classes. Only used for multiclass classification.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for positive class predictions.</span>
<span class="sd">    top_k : Optional[int]</span>
<span class="sd">        Number of highest probability or logits predictions to consider when</span>
<span class="sd">        computing multiclass or multilabel metrics. Default is None.</span>
<span class="sd">    num_labels : Optional[int]</span>
<span class="sd">        Number of labels. Only used for multilabel classification.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        Average to apply. If None, return scores for each class. One of:</span>

<span class="sd">        - ``micro``: Calculate metrics globally by counting the total true</span>
<span class="sd">            positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metrics for each label, and find their</span>
<span class="sd">            unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metrics for each label, and find their</span>
<span class="sd">            average weighted by support (the number of true instances for</span>
<span class="sd">            each label). This alters ``macro`` to account for label imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1]</span>
<span class="sd">        Value to return when there are no true positives or true negatives.</span>
<span class="sd">        If set to ``warn``, this acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    recall_score : float or numpy.ndarray</span>
<span class="sd">        Recall score. If ``average`` is not None or ``task`` is ``binary``,</span>
<span class="sd">        return a float. Otherwise, return a numpy.ndarray of recall scores</span>
<span class="sd">        for each class/label.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``task`` is not one of ``binary``, ``multiclass`` or ``multilabel``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; # (binary)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import recall</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 1, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0.4, 0.2, 0.0, 0.6, 0.9]</span>
<span class="sd">    &gt;&gt;&gt; recall(target, preds, task=&quot;binary&quot;)</span>
<span class="sd">    0.3333333333333333</span>

<span class="sd">    &gt;&gt;&gt; # (multiclass)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import recall</span>
<span class="sd">    &gt;&gt;&gt; target = [1, 1, 2, 0, 2, 2]</span>
<span class="sd">    &gt;&gt;&gt; preds = [1, 2, 2, 0, 2, 0]</span>
<span class="sd">    &gt;&gt;&gt; recall(target, preds, task=&quot;multiclass&quot;, num_classes=3)</span>
<span class="sd">    array([1.        , 0.5       , 0.66666667])</span>

<span class="sd">    &gt;&gt;&gt; # (multilabel)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import recall</span>
<span class="sd">    &gt;&gt;&gt; target = [[1, 0, 1], [0, 1, 0]]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.4, 0.2, 0.0], [0.6, 0.9, 0.1]]</span>
<span class="sd">    &gt;&gt;&gt; recall(target, preds, task=&quot;multilabel&quot;, num_labels=3)</span>
<span class="sd">    array([0., 1., 0.])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">binary_recall</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_classes</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;Number of classes must be specified for multiclass classification.&quot;</span>
        <span class="k">return</span> <span class="n">multiclass_recall</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;Number of labels must be specified for multilabel classification.&quot;</span>
        <span class="k">return</span> <span class="n">multilabel_recall</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;Task &#39;</span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">&#39; not supported, expected &#39;binary&#39;, &#39;multiclass&#39; or &quot;</span>
        <span class="sa">f</span><span class="s2">&quot;&#39;multilabel&#39;.&quot;</span>
    <span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

  

  <div class="footer-small-text">
    All <a href="https://github.com/VectorInstitute/cyclops">source code for cyclops</a> is freely available under the terms of an <a href="https://opensource.org/licenses/Apache-2.0">Apache-2.0</a> license.
  </div>

  <div class="footer-small-text">
    This work is made possible due to the data obtained from the
    General Medicine Inpatient Initiative (GEMINI).
  </div>

  <hr/>

  <div class="logo">
    <a class="logo" href="https://vectorinstitute.ai/">
      <span class="logo"></span>
      <img alt="Logo of the Vector Institute" style="width:90px; max-width:90px;" src="../../../../../_static/logos/vector_logo.png" />
    </a>
    <a class="logo" href="https://www.geminimedicine.ca/">
      <span class="logo"></span>
      <img alt="Logo of GEMINI" style="width:90px; max-width:90px;" src="../../../../../_static/logos/gemini_logo.png" />
    </a>
  </div>

  <div class="copyright">
    &copy; Copyright 2022, Vector AI Engineering
  </div>

  <div class="copyright">
    </p>
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using customised version of
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">base theme</a> provided by
    <a href="https://readthedocs.org">Read the Docs</a>.
  </div>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>