





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>cyclops.evaluation.metrics.precision_recall &mdash; cyclops  documentation</title>
      <link rel="stylesheet" href="../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/css/cyclops.css" type="text/css" />
      <link rel="stylesheet" href="../../../../_static/copybutton.css" type="text/css" />
    <link rel="shortcut icon" href="../../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../" id="documentation_options" src="../../../../_static/documentation_options.js"></script>
        <script src="../../../../_static/jquery.js"></script>
        <script src="../../../../_static/underscore.js"></script>
        <script src="../../../../_static/doctools.js"></script>
        <script src="../../../../_static/clipboard.min.js"></script>
        <script src="../../../../_static/copybutton.js"></script>
    <script src="../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
<script type="text/javascript">
  window.onload = function() {
    document.body.innerHTML = document.body.innerHTML.replace(/ module/g, '');
    document.body.innerHTML = document.body.innerHTML.replace(/ package/g, '');
  }
</script>

</head>

<body class="wy-body-for-nav">
  <!--
    Lie about what theme we really are when some RTD-injected JS fetches the
    full versions panel from the RTD API.  RTD's JS replaces the stub versions
    panel in the Sphinx-generated HTML with the full versions panel it fetches
    from the RTD API.  If the API thinks we're not sphinx_rtd_theme, it will
    serve us the wrong HTML and the panel will float as a "badge" when it
    shouldn't.  As a customized version of sphinx_rtd_theme, we really do want
    the same HTML it gets.  See also the diagnoses in
    <https://github.com/nextstrain/docs.nextstrain.org/issues/76>.

    This bit of JS finds the data RTD injects into the page and modifies it
    before the code that RTD injects runs and looks at the data.  RTD's
    <script>s (in <head>) run before this JS, but they wait until the DOM is
    ready to actually do any work.  This gives us a chance to modify the data
    during DOM load before the RTD code actually uses it.

      -trs, 27 Jan 2022
  -->
  <script>
    (() => {
      try {
        console.log("Lying about the theme to RTD's JS so the versions panel works properly. üôà");

        /* Update global variable, which is used in the request to get the RTD
         * "footer" that includes the versions panel.
         */
        if (window.READTHEDOCS_DATA)
          window.READTHEDOCS_DATA.theme = "sphinx_rtd_theme";

        /* Update stored JSON in case anything else deserializes it later.
         * Comments in the RTD-injected HTML source claim the global variable
         * above is deprecated.
         */
        var script = document.querySelector("#READTHEDOCS_DATA");
        if (script)
          script.innerHTML = JSON.stringify({ ...JSON.parse(script.innerHTML), theme: "sphinx_rtd_theme" });
      }
      catch (err) {
        console.log("Lying about the theme to RTD's JS failed‚Ä¶ oh well. ü§∑", err);
      }
    })();
  </script>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #efeeed" >




  <a href="https://vectorinstitute.github.io/cyclops/">
    <img src="../../../../_static/cyclops_logo-dark.png" class="logo" alt="Logo"/>
  </a>



  <div class="subproject">
    <a href="../../../../index.html" class="project-name" alt="Documentation Home">
      cyclops
    </a>

    
    
    

  </div>




<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../intro.html">üê£ Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../intro.html#documentation">üìö Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../intro.html#notebooks">üéì Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../design.html">Framework Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../gemini_hpc.html">Using cyclops on the GEMINI HPC</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../contributing.html">Contributing to cyclops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../coverage.html">Coverage report</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../api.html">API Documentation</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #efeeed" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../index.html">cyclops</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  

  
  
    <li><a href="https://vectorinstitute.github.io/cyclops/">Home</a></li>
    <li><a href="../../../../index.html">cyclops</a></li>
  

  
  
    <li><a href="../../../index.html">Module code</a></li>
  

  

      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for cyclops.evaluation.metrics.precision_recall</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Classes for computing precision and recall metrics.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span>

<span class="kn">from</span> <span class="nn">cyclops.evaluation.metrics.functional.precision_recall</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_precision_recall_reduce</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">cyclops.evaluation.metrics.metric</span> <span class="kn">import</span> <span class="n">Metric</span>
<span class="kn">from</span> <span class="nn">cyclops.evaluation.metrics.stat_scores</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">BinaryStatScores</span><span class="p">,</span>
    <span class="n">MulticlassStatScores</span><span class="p">,</span>
    <span class="n">MultilabelStatScores</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">cyclops.evaluation.metrics.utils</span> <span class="kn">import</span> <span class="n">_check_average_arg</span>


<div class="viewcode-block" id="BinaryPrecision"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.BinaryPrecision">[docs]</a><span class="k">class</span> <span class="nc">BinaryPrecision</span><span class="p">(</span><span class="n">BinaryStatScores</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the precision score for binary classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        pos_label : int, default=1</span>
<span class="sd">            The label of the positive class.</span>
<span class="sd">        threshold : float, default=0.5</span>
<span class="sd">            Threshold for deciding the positive class.</span>
<span class="sd">        zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">            Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">            acts as 0, but warnings are also raised.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import BinaryPrecision</span>
<span class="sd">        &gt;&gt;&gt; target = [0, 1, 0, 1]</span>
<span class="sd">        &gt;&gt;&gt; preds = [0, 1, 1, 1]</span>
<span class="sd">        &gt;&gt;&gt; metric = BinaryPrecision()</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        0.6666666666666666</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 0, 1], [0, 0, 1, 1]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[0.1, 0.9, 0.8, 0.2], [0.2, 0.3, 0.6, 0.1]]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        0.6666666666666666</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span> <span class="o">=</span> <span class="n">zero_division</span>

<div class="viewcode-block" id="BinaryPrecision.compute"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.BinaryPrecision.compute">[docs]</a>    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute the precision score from the state.&quot;&quot;&quot;</span>
        <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
            <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
            <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="MulticlassPrecision"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.MulticlassPrecision">[docs]</a><span class="k">class</span> <span class="nc">MulticlassPrecision</span><span class="p">(</span><span class="n">MulticlassStatScores</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the precision score for multiclass classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        num_classes : int</span>
<span class="sd">            Number of classes in the dataset.</span>
<span class="sd">        top_k : int, optional</span>
<span class="sd">            If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">            be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">            set to 1.</span>
<span class="sd">        average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">           If ``None``, return the score for each class. Otherwise, use one of the</span>
<span class="sd">           following options to compute the average score:</span>
<span class="sd">                - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">                  positives and false positives.</span>
<span class="sd">                - ``macro``: Calculate metric for each class, and find their</span>
<span class="sd">                  unweighted mean. This does not take class imbalance into account.</span>
<span class="sd">                - ``weighted``: Calculate metric for each class, and find their</span>
<span class="sd">                  average weighted by the support (the number of true instances</span>
<span class="sd">                  for each class). This alters &quot;macro&quot; to account for class</span>
<span class="sd">                  imbalance.</span>
<span class="sd">        zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">            Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">            acts as 0, but warnings are also raised.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import MulticlassPrecision</span>
<span class="sd">        &gt;&gt;&gt; target = [0, 1, 2, 0]</span>
<span class="sd">        &gt;&gt;&gt; preds = [0, 2, 1, 0]</span>
<span class="sd">        &gt;&gt;&gt; metric = MulticlassPrecision(num_classes=3, average=None)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        array([1. , 0. , 0.])</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 2, 0], [2, 1, 2, 0]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [</span>
<span class="sd">        ...     [[0.1, 0.6, 0.3],</span>
<span class="sd">        ...      [0.05, 0.1, 0.85],</span>
<span class="sd">        ...      [0.2, 0.7, 0.1],</span>
<span class="sd">        ...      [0.9, 0.05, 0.05]],</span>
<span class="sd">        ...     [[0.1, 0.6, 0.3],</span>
<span class="sd">        ...      [0.05, 0.1, 0.85],</span>
<span class="sd">        ...      [0.2, 0.7, 0.1],</span>
<span class="sd">        ...      [0.9, 0.05, 0.05]]</span>
<span class="sd">        ... ]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        array([1., 0., 0.])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span> <span class="n">classwise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="n">_check_average_arg</span><span class="p">(</span><span class="n">average</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">average</span> <span class="o">=</span> <span class="n">average</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span> <span class="o">=</span> <span class="n">zero_division</span>

<div class="viewcode-block" id="MulticlassPrecision.compute"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.MulticlassPrecision.compute">[docs]</a>    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute the precision score from the state.&quot;&quot;&quot;</span>
        <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
            <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
            <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">average</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="MultilabelPrecision"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.MultilabelPrecision">[docs]</a><span class="k">class</span> <span class="nc">MultilabelPrecision</span><span class="p">(</span><span class="n">MultilabelStatScores</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the precision score for multilabel classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        num_labels : int</span>
<span class="sd">            Number of labels for the task.</span>
<span class="sd">        threshold : float, default=0.5</span>
<span class="sd">            Threshold for deciding the positive class.</span>
<span class="sd">        top_k : int, optional</span>
<span class="sd">            If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">            be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">            set to 1.</span>
<span class="sd">        average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">            If ``None``, return the precision score for each label. Otherwise,</span>
<span class="sd">            use one of the following options to compute the average precision score:</span>
<span class="sd">                - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">                  positives and false positives.</span>
<span class="sd">                - ``macro``: Calculate metric for each label, and find their</span>
<span class="sd">                  unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">                - ``weighted``: Calculate metric for each label, and find their</span>
<span class="sd">                  average weighted by the support (the number of true instances</span>
<span class="sd">                  for each label). This alters &quot;macro&quot; to account for label</span>
<span class="sd">                  imbalance.</span>
<span class="sd">        zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">            Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">            acts as 0, but warnings are also raised.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import MultilabelPrecision</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1], [1, 1]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[0.1, 0.9], [0.2, 0.8]]</span>
<span class="sd">        &gt;&gt;&gt; metric = MultilabelPrecision(num_labels=2, average=None)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        array([0., 1.])</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[[0, 1], [1, 1]], [[1, 1], [1, 0]]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [</span>
<span class="sd">        ...     [[0.1, 0.7], [0.2, 0.8]],</span>
<span class="sd">        ...     [[0.5, 0.9], [0.3, 0.4]]</span>
<span class="sd">        ... ]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        array([1., 1.])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
            <span class="n">labelwise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="n">_check_average_arg</span><span class="p">(</span><span class="n">average</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">average</span> <span class="o">=</span> <span class="n">average</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span> <span class="o">=</span> <span class="n">zero_division</span>

<div class="viewcode-block" id="MultilabelPrecision.compute"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.MultilabelPrecision.compute">[docs]</a>    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute the precision score from the state.&quot;&quot;&quot;</span>
        <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
            <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
            <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;precision&quot;</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">average</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="Precision"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.Precision">[docs]</a><span class="k">class</span> <span class="nc">Precision</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the precision score for different types of classification tasks.</span>

<span class="sd">    This metric can be used for binary, multiclass, and multilabel classification</span>
<span class="sd">    tasks. It creates the appropriate metric based on the ``task`` parameter.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        task : Literal[&quot;binary&quot;, &quot;multiclass&quot;, &quot;multilabel&quot;]</span>
<span class="sd">            Type of classification task.</span>
<span class="sd">        pos_label : int, default=1</span>
<span class="sd">            Label to consider as positive for binary classification tasks.</span>
<span class="sd">        num_classes : int, default=None</span>
<span class="sd">            Number of classes for the task. Required if ``task`` is ``&quot;multiclass&quot;``.</span>
<span class="sd">        threshold : float, default=0.5</span>
<span class="sd">            Threshold for deciding the positive class. Only used if ``task`` is</span>
<span class="sd">            ``&quot;binary&quot;`` or ``&quot;multilabel&quot;``.</span>
<span class="sd">        top_k : int, optional</span>
<span class="sd">            If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">            be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">            set to 1. Only used if ``task`` is ``&quot;multiclass&quot;`` or ``&quot;multilabel&quot;``.</span>
<span class="sd">        num_labels : int, default=None</span>
<span class="sd">            Number of labels for the task. Required if ``task`` is ``&quot;multilabel&quot;``.</span>
<span class="sd">        average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">            If ``None``, return the precision score for each label/class. Otherwise,</span>
<span class="sd">            use one of the following options to compute the average precision score:</span>
<span class="sd">                - ``micro``: Calculate metrics globally by counting the total true</span>
<span class="sd">                  positives and false positives.</span>
<span class="sd">                - ``macro``: Calculate metrics for each class/label, and find their</span>
<span class="sd">                  unweighted mean. This does not take label/class imbalance into</span>
<span class="sd">                  account.</span>
<span class="sd">                - ``weighted``: Calculate metrics for each label/class, and find</span>
<span class="sd">                  their average weighted by support (the number of true instances</span>
<span class="sd">                  for each label/class). This alters ``macro`` to account for</span>
<span class="sd">                  label/class imbalance.</span>
<span class="sd">        zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">            Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">            acts as 0, but warnings are also raised.</span>

<span class="sd">    Examples (binary)</span>
<span class="sd">    -----------------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import Precision</span>
<span class="sd">        &gt;&gt;&gt; target = [0, 1, 0, 1]</span>
<span class="sd">        &gt;&gt;&gt; preds = [0, 1, 1, 1]</span>
<span class="sd">        &gt;&gt;&gt; metric = Precision(task=&quot;binary&quot;)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        0.6666666666666666</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 0, 1], [0, 0, 1, 1]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[0.1, 0.9, 0.8, 0.2], [0.2, 0.3, 0.6, 0.1]]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        0.6666666666666666</span>

<span class="sd">    Examples (multiclass)</span>
<span class="sd">    ---------------------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import Precision</span>
<span class="sd">        &gt;&gt;&gt; target = [0, 1, 2, 0]</span>
<span class="sd">        &gt;&gt;&gt; preds = [0, 2, 1, 0]</span>
<span class="sd">        &gt;&gt;&gt; metric = Precision(task=&quot;multiclass&quot;, num_classes=3)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        array([1. , 0. , 0.])</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 2, 0], [2, 1, 2, 0]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [</span>
<span class="sd">        ...     [[0.1, 0.6, 0.3],</span>
<span class="sd">        ...      [0.05, 0.1, 0.85],</span>
<span class="sd">        ...      [0.2, 0.7, 0.1],</span>
<span class="sd">        ...      [0.9, 0.05, 0.05]],</span>
<span class="sd">        ...     [[0.1, 0.6, 0.3],</span>
<span class="sd">        ...      [0.05, 0.1, 0.85],</span>
<span class="sd">        ...      [0.2, 0.7, 0.1],</span>
<span class="sd">        ...      [0.9, 0.05, 0.05]]</span>
<span class="sd">        ... ]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        array([1., 0., 0.])</span>

<span class="sd">    Examples (multilabel)</span>
<span class="sd">    ---------------------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import Precision</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1], [1, 1]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[0.1, 0.9], [0.2, 0.8]]</span>
<span class="sd">        &gt;&gt;&gt; metric = Precision(task=&quot;multilabel&quot;, num_labels=2)</span>
<span class="sd">        &gt;&gt;&gt; metric.update_state(target, preds)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        array([0., 1.])</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[[0, 1], [1, 1]], [[1, 1], [1, 0]]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [</span>
<span class="sd">        ...     [[0.1, 0.7], [0.2, 0.8]],</span>
<span class="sd">        ...     [[0.5, 0.9], [0.3, 0.4]]</span>
<span class="sd">        ... ]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        array([1., 1.])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__new__</span><span class="p">(</span>  <span class="c1"># type: ignore # mypy expects a subclass of Precision</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">task</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">],</span>
        <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Metric</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create a task-specific precision metric.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">BinaryPrecision</span><span class="p">(</span>
                <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_classes</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="s2">&quot;Number of classes must be specified for multiclass classification.&quot;</span>
            <span class="k">return</span> <span class="n">MulticlassPrecision</span><span class="p">(</span>
                <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
                <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
                <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
                <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="s2">&quot;Number of labels must be specified for multilabel classification.&quot;</span>
            <span class="k">return</span> <span class="n">MultilabelPrecision</span><span class="p">(</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
                <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
                <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
                <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Task &#39;</span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">&#39; not supported, expected &#39;binary&#39;, &#39;multiclass&#39; or &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;multilabel&#39;.&quot;</span>
        <span class="p">)</span></div>


<div class="viewcode-block" id="BinaryRecall"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.BinaryRecall">[docs]</a><span class="k">class</span> <span class="nc">BinaryRecall</span><span class="p">(</span><span class="n">BinaryStatScores</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Computes recall score for binary classification.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        pos_label : int, default=1</span>
<span class="sd">            Label of the positive class.</span>
<span class="sd">        threshold : float, default=0.5</span>
<span class="sd">            Threshold for deciding the positive class.</span>
<span class="sd">        zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">            Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">            acts as 0, but warnings are also raised.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import BinaryRecall</span>
<span class="sd">        &gt;&gt;&gt; target = [0, 1, 0, 1]</span>
<span class="sd">        &gt;&gt;&gt; preds = [0, 1, 1, 0]</span>
<span class="sd">        &gt;&gt;&gt; metric = Recall()</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        0.5</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 0, 1], [0, 0, 1, 1]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[0.1, 0.9, 0.8, 0.2], [0.2, 0.3, 0.6, 0.1]]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        0.5</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span> <span class="o">=</span> <span class="n">zero_division</span>

<div class="viewcode-block" id="BinaryRecall.compute"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.BinaryRecall.compute">[docs]</a>    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute the recall score from the state.&quot;&quot;&quot;</span>
        <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
            <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
            <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="MulticlassRecall"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.MulticlassRecall">[docs]</a><span class="k">class</span> <span class="nc">MulticlassRecall</span><span class="p">(</span><span class="n">MulticlassStatScores</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the recall score for multiclass classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        num_classes : int</span>
<span class="sd">            Number of classes in the dataset.</span>
<span class="sd">        top_k : int, optional</span>
<span class="sd">            If given, and predictions are probabilities/logits, the recall will</span>
<span class="sd">            be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">            set to 1.</span>
<span class="sd">        average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">           If ``None``, return the recall score for each class. Otherwise,</span>
<span class="sd">           use one of the following options to compute the average score:</span>
<span class="sd">                - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">                  positives and false negatives.</span>
<span class="sd">                - ``macro``: Calculate metric for each class, and find their</span>
<span class="sd">                  unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">                - ``weighted``: Calculate metric for each class, and find their</span>
<span class="sd">                  average weighted by the support (the number of true instances</span>
<span class="sd">                  for each class). This alters &quot;macro&quot; to account for class</span>
<span class="sd">                  imbalance.</span>
<span class="sd">        zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">            Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">            acts as 0, but warnings are also raised.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import MulticlassRecall</span>
<span class="sd">        &gt;&gt;&gt; target = [0, 1, 2, 0]</span>
<span class="sd">        &gt;&gt;&gt; preds = [2, 0, 2, 1]</span>
<span class="sd">        &gt;&gt;&gt; metric = MulticlassRecall(num_classes=3)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        array([0., 0., 1.])</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 2, 0], [2, 1, 2, 0]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [</span>
<span class="sd">        ...     [[0.1, 0.6, 0.3],</span>
<span class="sd">        ...      [0.05, 0.1, 0.85],</span>
<span class="sd">        ...      [0.2, 0.7, 0.1],</span>
<span class="sd">        ...      [0.9, 0.05, 0.05]],</span>
<span class="sd">        ...     [[0.1, 0.6, 0.3],</span>
<span class="sd">        ...      [0.05, 0.1, 0.85],</span>
<span class="sd">        ...      [0.2, 0.7, 0.1],</span>
<span class="sd">        ...      [0.9, 0.05, 0.05]]</span>
<span class="sd">        ... ]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        array([0.66666667, 0.        , 0.        ])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span> <span class="n">classwise</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">average</span> <span class="o">=</span> <span class="n">average</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span> <span class="o">=</span> <span class="n">zero_division</span>

<div class="viewcode-block" id="MulticlassRecall.compute"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.MulticlassRecall.compute">[docs]</a>    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute the recall score from the state.&quot;&quot;&quot;</span>
        <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
            <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
            <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">average</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="MultilabelRecall"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.MultilabelRecall">[docs]</a><span class="k">class</span> <span class="nc">MultilabelRecall</span><span class="p">(</span><span class="n">MultilabelStatScores</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the recall score for multilabel classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        num_labels : int</span>
<span class="sd">            Number of labels in the dataset.</span>
<span class="sd">        threshold : float, default=0.5</span>
<span class="sd">            Threshold for deciding the positive class.</span>
<span class="sd">        average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">            If ``None``, return the score for each class. Otherwise,</span>
<span class="sd">            use one of the following options to compute the average score:</span>
<span class="sd">                - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">                    positives and false negatives.</span>
<span class="sd">                - ``macro``: Calculate metric for each label, and find their</span>
<span class="sd">                    unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">                - ``weighted``: Calculate metric for each label, and find their</span>
<span class="sd">                    average weighted by the support (the number of true instances</span>
<span class="sd">                    for each label). This alters &quot;macro&quot; to account for label</span>
<span class="sd">                    imbalance.</span>
<span class="sd">        zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">            Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">            acts as 0, but warnings are also raised.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import MultilabelRecall</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 0, 1], [0, 0, 1, 1]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[0.1, 0.9, 0.8, 0.2], [0.2, 0.3, 0.6, 0.1]]</span>
<span class="sd">        &gt;&gt;&gt; metric = MultilabelRecall(num_labels=4)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        array([0., 1., 1. , 0. ])</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[[0, 1, 0, 1], [0, 0, 1, 1]], [[0, 1, 0, 1], [0, 0, 1, 1]]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[[0.1, 0.9, 0.8, 0.2], [0.2, 0.3, 0.6, 0.1]],</span>
<span class="sd">        ...          [[0.1, 0.9, 0.8, 0.2], [0.2, 0.3, 0.6, 0.1]]]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        array([0., 1., 1., 0.])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
            <span class="n">labelwise</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">average</span> <span class="o">=</span> <span class="n">average</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span> <span class="o">=</span> <span class="n">zero_division</span>

<div class="viewcode-block" id="MultilabelRecall.compute"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.MultilabelRecall.compute">[docs]</a>    <span class="k">def</span> <span class="nf">compute</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Compute the recall score from the state.&quot;&quot;&quot;</span>
        <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_final_state</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">_precision_recall_reduce</span><span class="p">(</span>
            <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
            <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
            <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
            <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;recall&quot;</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">average</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span></div></div>


<div class="viewcode-block" id="Recall"><a class="viewcode-back" href="../../../../reference/api/cyclops.evaluation.metrics.precision_recall.html#cyclops.evaluation.metrics.precision_recall.Recall">[docs]</a><span class="k">class</span> <span class="nc">Recall</span><span class="p">(</span><span class="n">Metric</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the recall score for different types of classification tasks.</span>

<span class="sd">    This metric can be used for binary, multiclass, and multilabel classification</span>
<span class="sd">    tasks. It creates the appropriate class based on the ``task`` parameter.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">        task : Literal[&quot;binary&quot;, &quot;multiclass&quot;, &quot;multilabel&quot;]</span>
<span class="sd">            Type of classification task.</span>
<span class="sd">        pos_label : int, default=1</span>
<span class="sd">            Label to consider as positive for binary classification tasks.</span>
<span class="sd">        num_classes : int, default=None</span>
<span class="sd">            Number of classes for the task. Required if ``task`` is ``&quot;multiclass&quot;``.</span>
<span class="sd">        threshold : float, default=0.5</span>
<span class="sd">            Threshold for deciding the positive class. Only used if ``task`` is</span>
<span class="sd">            ``&quot;binary&quot;`` or ``&quot;multilabel&quot;``.</span>
<span class="sd">        top_k : int, optional</span>
<span class="sd">            If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">            be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">            set to 1. Only used if ``task`` is ``&quot;multiclass&quot;`` or ``&quot;multilabel&quot;``.</span>
<span class="sd">        num_labels : int, default=None</span>
<span class="sd">            Number of labels for the task. Required if ``task`` is ``&quot;multilabel&quot;``.</span>
<span class="sd">        average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">            If ``None``, return the recall score for each label/class. Otherwise,</span>
<span class="sd">            use one of the following options to compute the average score:</span>
<span class="sd">                - ``micro``: Calculate metrics globally by counting the total true</span>
<span class="sd">                  positives and false negatives.</span>
<span class="sd">                - ``macro``: Calculate metrics for each class/label, and find their</span>
<span class="sd">                  unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">                - ``weighted``: Calculate metrics for each label/class, and find</span>
<span class="sd">                  their average weighted by support (the number of true instances</span>
<span class="sd">                  for each label/class). This alters ``macro`` to account for</span>
<span class="sd">                  label/class imbalance.</span>
<span class="sd">        zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">            Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">            acts as 0, but warnings are also raised.</span>

<span class="sd">    Examples (binary)</span>
<span class="sd">    -----------------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import Recall</span>
<span class="sd">        &gt;&gt;&gt; target = [0, 1, 0, 1]</span>
<span class="sd">        &gt;&gt;&gt; preds = [0, 1, 1, 1]</span>
<span class="sd">        &gt;&gt;&gt; metric = Recall(task=&quot;binary&quot;)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        1.</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 0, 1], [0, 0, 1, 1]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[0.1, 0.9, 0.8, 0.2], [0.2, 0.3, 0.6, 0.1]]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        0.5</span>

<span class="sd">    Examples (multiclass)</span>
<span class="sd">    ---------------------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import Recall</span>
<span class="sd">        &gt;&gt;&gt; target = [0, 1, 2, 0]</span>
<span class="sd">        &gt;&gt;&gt; preds = [0, 2, 1, 0]</span>
<span class="sd">        &gt;&gt;&gt; metric = Recall(task=&quot;multiclass&quot;, num_classes=3)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        array([1. , 0. , 0.])</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1, 2, 0], [2, 1, 2, 0]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [</span>
<span class="sd">        ...     [[0.1, 0.6, 0.3],</span>
<span class="sd">        ...      [0.05, 0.1, 0.85],</span>
<span class="sd">        ...      [0.2, 0.7, 0.1],</span>
<span class="sd">        ...      [0.9, 0.05, 0.05]],</span>
<span class="sd">        ...     [[0.1, 0.6, 0.3],</span>
<span class="sd">        ...      [0.05, 0.1, 0.85],</span>
<span class="sd">        ...      [0.2, 0.7, 0.1],</span>
<span class="sd">        ...      [0.9, 0.05, 0.05]]</span>
<span class="sd">        ... ]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">       array([0.66666667, 0.        , 0.        ])</span>

<span class="sd">    Examples (multilabel)</span>
<span class="sd">    ---------------------</span>
<span class="sd">        &gt;&gt;&gt; from cyclops.evaluation.metrics import Recall</span>
<span class="sd">        &gt;&gt;&gt; target = [[0, 1], [1, 1]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [[0.1, 0.9], [0.2, 0.8]]</span>
<span class="sd">        &gt;&gt;&gt; metric = Recall(task=&quot;multilabel&quot;, num_labels=2)</span>
<span class="sd">        &gt;&gt;&gt; metric(target, preds)</span>
<span class="sd">        array([0., 1.])</span>
<span class="sd">        &gt;&gt;&gt; metric.reset_state()</span>
<span class="sd">        &gt;&gt;&gt; target = [[[0, 1], [1, 1]], [[1, 1], [1, 0]]]</span>
<span class="sd">        &gt;&gt;&gt; preds = [</span>
<span class="sd">        ...     [[0.1, 0.7], [0.2, 0.8]],</span>
<span class="sd">        ...     [[0.5, 0.9], [0.3, 0.4]]</span>
<span class="sd">        ... ]</span>
<span class="sd">        &gt;&gt;&gt; for t, p in zip(target, preds):</span>
<span class="sd">        ...     metric.update_state(t, p)</span>
<span class="sd">        &gt;&gt;&gt; metric.compute()</span>
<span class="sd">        array([0.33333333, 1.        ])</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__new__</span><span class="p">(</span>  <span class="c1"># type: ignore # mypy expects a subclass of Recall</span>
        <span class="bp">cls</span><span class="p">,</span>
        <span class="n">task</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">],</span>
        <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Metric</span><span class="p">:</span>
        <span class="sd">&quot;&quot;&quot;Create a task-specific metric for computing the recall score.&quot;&quot;&quot;</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">BinaryRecall</span><span class="p">(</span>
                <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span> <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_classes</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="s2">&quot;Number of classes must be specified for multiclass classification.&quot;</span>
            <span class="k">return</span> <span class="n">MulticlassRecall</span><span class="p">(</span>
                <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
                <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
                <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
                <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">:</span>
            <span class="k">assert</span> <span class="p">(</span>
                <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span>
            <span class="p">),</span> <span class="s2">&quot;Number of labels must be specified for multilabel classification.&quot;</span>
            <span class="k">return</span> <span class="n">MultilabelRecall</span><span class="p">(</span>
                <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
                <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
                <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
                <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
                <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
            <span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Task &#39;</span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2">&#39; not supported, expected &#39;binary&#39;, &#39;multiclass&#39; or &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;&#39;multilabel&#39;.&quot;</span>
        <span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

  

  <div class="citation">
    CyclOps team <i>et al.,</i>
    <a href="https://vectorinstitute.github.io/cyclops/">CyclOps: Cyclical development towards Operationalizing ML models for health</a>
    <i>, TBD</i> (2022)
  </def>


  <p class="avatar">cyclops is built by</p>
  <div class="avatar">
    
    
    <span>
      <a href="https://github.com/amrit110">
        <img src="../../../../_static/team/amrit-krishnan.jpg" width="32"/>
        Amrit Krishnan
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/KadenMc">
        <img src="../../../../_static/team/kaden-mckeen.jpg" width="32"/>
        Kaden McKeen
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/vsubasri">
        <img src="../../../../_static/team/valli-subasri.jpg" width="32"/>
        Valli Subasri
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/a-kore">
        <img src="../../../../_static/team/ali-kore.jpg" width="32"/>
        Ali Kore
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/fcogidi">
        <img src="../../../../_static/team/franklin-ogidi.jpg" width="32"/>
        Franklin Ogidi
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/dhrumilp15">
        <img src="../../../../_static/team/dhrumil-patel.jpg" width="32"/>
        Dhrumil Patel
      </a>
    </span>
    ,
  </div>


  <div class="footer-small-text">
    All <a href="https://github.com/VectorInstitute/cyclops">source code for cyclops</a> is freely available under the terms of an <a href="https://opensource.org/licenses/Apache-2.0">Apache-2.0</a> license.
  </div>

  <div class="footer-small-text">
    This work is made possible due to the data obtained from the
    General Medicine Inpatient Initiative (GEMINI).
  </div>

  <hr/>

  <div class="logo">
    <a class="logo" href="https://vectorinstitute.ai/">
      <span class="logo"></span>
      <img alt="Logo of the Vector Institute" style="width:90px; max-width:90px;" src="../../../../_static/logos/vector_logo.png" />
    </a>
    <a class="logo" href="https://www.geminimedicine.ca/">
      <span class="logo"></span>
      <img alt="Logo of GEMINI" style="width:90px; max-width:90px;" src="../../../../_static/logos/gemini_logo.png" />
    </a>
  </div>

  <div class="copyright">
    &copy; Copyright 2022, Vector AI Engineering
  </div>

  <div class="copyright">
    </p>
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using customised version of
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">base theme</a> provided by
    <a href="https://readthedocs.org">Read the Docs</a>.
  </div>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>