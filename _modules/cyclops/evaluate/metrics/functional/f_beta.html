





<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>cyclops.evaluate.metrics.functional.f_beta &mdash; cyclops  documentation</title>
      <link rel="stylesheet" href="../../../../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/css/cyclops.css" type="text/css" />
      <link rel="stylesheet" href="../../../../../_static/copybutton.css" type="text/css" />
    <link rel="shortcut icon" href="../../../../../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../../../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../../../../" id="documentation_options" src="../../../../../_static/documentation_options.js"></script>
        <script src="../../../../../_static/jquery.js"></script>
        <script src="../../../../../_static/underscore.js"></script>
        <script src="../../../../../_static/doctools.js"></script>
        <script src="../../../../../_static/clipboard.min.js"></script>
        <script src="../../../../../_static/copybutton.js"></script>
    <script src="../../../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../../search.html" />
<script type="text/javascript">
  window.onload = function() {
    document.body.innerHTML = document.body.innerHTML.replace(/ module/g, '');
    document.body.innerHTML = document.body.innerHTML.replace(/ package/g, '');
  }
</script>

</head>

<body class="wy-body-for-nav">
  <!--
    Lie about what theme we really are when some RTD-injected JS fetches the
    full versions panel from the RTD API.  RTD's JS replaces the stub versions
    panel in the Sphinx-generated HTML with the full versions panel it fetches
    from the RTD API.  If the API thinks we're not sphinx_rtd_theme, it will
    serve us the wrong HTML and the panel will float as a "badge" when it
    shouldn't.  As a customized version of sphinx_rtd_theme, we really do want
    the same HTML it gets.  See also the diagnoses in
    <https://github.com/nextstrain/docs.nextstrain.org/issues/76>.

    This bit of JS finds the data RTD injects into the page and modifies it
    before the code that RTD injects runs and looks at the data.  RTD's
    <script>s (in <head>) run before this JS, but they wait until the DOM is
    ready to actually do any work.  This gives us a chance to modify the data
    during DOM load before the RTD code actually uses it.

      -trs, 27 Jan 2022
  -->
  <script>
    (() => {
      try {
        console.log("Lying about the theme to RTD's JS so the versions panel works properly. üôà");

        /* Update global variable, which is used in the request to get the RTD
         * "footer" that includes the versions panel.
         */
        if (window.READTHEDOCS_DATA)
          window.READTHEDOCS_DATA.theme = "sphinx_rtd_theme";

        /* Update stored JSON in case anything else deserializes it later.
         * Comments in the RTD-injected HTML source claim the global variable
         * above is deprecated.
         */
        var script = document.querySelector("#READTHEDOCS_DATA");
        if (script)
          script.innerHTML = JSON.stringify({ ...JSON.parse(script.innerHTML), theme: "sphinx_rtd_theme" });
      }
      catch (err) {
        console.log("Lying about the theme to RTD's JS failed‚Ä¶ oh well. ü§∑", err);
      }
    })();
  </script>

  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search"  style="background: #efeeed" >




  <a href="https://vectorinstitute.github.io/cyclops/">
    <img src="../../../../../_static/cyclops_logo-dark.png" class="logo" alt="Logo"/>
  </a>



  <div class="subproject">
    <a href="../../../../../index.html" class="project-name" alt="Documentation Home">
      cyclops
    </a>

    
    
    

  </div>




<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>


        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html">üê£ Getting Started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html#developing">üßëüèø‚Äçüíª Developing</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html#documentation">üìö Documentation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html#notebooks">üìì Notebooks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../intro.html#citation">üéì Citation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../design.html">Framework Design</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../contributing.html">Contributing to cyclops</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../../api.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu"  style="background: #efeeed" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../../../index.html">cyclops</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
  

  
  
    <li><a href="https://vectorinstitute.github.io/cyclops/">Home</a></li>
    <li><a href="../../../../../index.html">cyclops</a></li>
  

  
  
    <li><a href="../../../../index.html">Module code</a></li>
  

  

      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for cyclops.evaluate.metrics.functional.f_beta</h1><div class="highlight"><pre>
<span></span><span class="sd">&quot;&quot;&quot;Functions for computing F-beta and F1 scores for different input types.&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.typing</span> <span class="kn">import</span> <span class="n">ArrayLike</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics._classification</span> <span class="kn">import</span> <span class="n">_prf_divide</span>

<span class="kn">from</span> <span class="nn">cyclops.evaluate.metrics.functional.stat_scores</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_binary_stat_scores_args_check</span><span class="p">,</span>
    <span class="n">_binary_stat_scores_format</span><span class="p">,</span>
    <span class="n">_binary_stat_scores_update</span><span class="p">,</span>
    <span class="n">_multiclass_stat_scores_format</span><span class="p">,</span>
    <span class="n">_multiclass_stat_scores_update</span><span class="p">,</span>
    <span class="n">_multilabel_stat_scores_format</span><span class="p">,</span>
    <span class="n">_multilabel_stat_scores_update</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">cyclops.evaluate.metrics.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">_check_average_arg</span><span class="p">,</span>
    <span class="n">_get_value_if_singleton_array</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">_fbeta_reduce</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">tp</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">fp</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">fn</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">],</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Compute the F-beta score, a generalization of F-measure.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    tp : numpy.ndarray</span>
<span class="sd">        True positives per class.</span>
<span class="sd">    fp : numpy.ndarray</span>
<span class="sd">        False positives per class.</span>
<span class="sd">    fn : numpy.ndarray</span>
<span class="sd">        False negatives per class.</span>
<span class="sd">    beta : float</span>
<span class="sd">        Weight of precision in harmonic mean (beta &lt; 1 lends more weight to</span>
<span class="sd">        precision, beta &gt; 1 favors recall).</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the score for each class. Otherwise,</span>
<span class="sd">        use one of the following options to compute the average score:</span>

<span class="sd">        - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">            positives, false positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metric for each label, and find their</span>
<span class="sd">            unweighted mean. This does not take label/class imbalance</span>
<span class="sd">            into account.</span>
<span class="sd">        - ``weighted``: Calculate metric for each label/class, and find their</span>
<span class="sd">            average weighted by the support (the number of true instances</span>
<span class="sd">            for each label/class). This alters &quot;macro&quot; to account for</span>
<span class="sd">            label/class imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    result : float or numpy.ndarray</span>
<span class="sd">        F-beta score or array of scores if ``average=None``.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        if beta is less than 0.</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_beta</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>

    <span class="n">beta2</span> <span class="o">=</span> <span class="n">beta</span><span class="o">**</span><span class="mi">2</span>

    <span class="n">numerator</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">tp</span>
    <span class="n">denominator</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">beta2</span><span class="p">)</span> <span class="o">*</span> <span class="n">tp</span> <span class="o">+</span> <span class="n">beta2</span> <span class="o">*</span> <span class="n">fn</span> <span class="o">+</span> <span class="n">fp</span>

    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;micro&quot;</span><span class="p">:</span>
        <span class="n">numerator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">numerator</span><span class="p">))</span>
        <span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">denominator</span><span class="p">))</span>

    <span class="n">score</span> <span class="o">=</span> <span class="n">_prf_divide</span><span class="p">(</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">numerator</span><span class="p">)</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span> <span class="k">else</span> <span class="n">numerator</span><span class="p">,</span>
        <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">denominator</span><span class="p">)</span> <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isscalar</span><span class="p">(</span><span class="n">tp</span><span class="p">)</span> <span class="k">else</span> <span class="n">denominator</span><span class="p">,</span>
        <span class="n">metric</span><span class="o">=</span><span class="s2">&quot;f-score&quot;</span><span class="p">,</span>
        <span class="n">modifier</span><span class="o">=</span><span class="s2">&quot;true nor predicted&quot;</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">warn_for</span><span class="o">=</span><span class="s2">&quot;f-score&quot;</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="k">if</span> <span class="n">average</span> <span class="o">==</span> <span class="s2">&quot;weighted&quot;</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="n">tp</span> <span class="o">+</span> <span class="n">fn</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">weights</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">zero_division</span> <span class="ow">in</span> <span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">]:</span>
                <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">result</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">weights</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">average</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="n">score</span><span class="o">.</span><span class="n">ndim</span> <span class="o">!=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">score</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">score</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">weights</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">result</span> <span class="o">=</span> <span class="n">_get_value_if_singleton_array</span><span class="p">(</span><span class="n">score</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">result</span>


<span class="k">def</span> <span class="nf">_check_beta</span><span class="p">(</span><span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Check the ``beta`` argument for F-beta metrics.&quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">beta</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;beta should be &gt;=0 in the F-beta score&quot;</span><span class="p">)</span>


<div class="viewcode-block" id="binary_fbeta_score"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.f_beta.binary_fbeta_score.html#cyclops.evaluate.metrics.functional.f_beta.binary_fbeta_score">[docs]</a><span class="k">def</span> <span class="nf">binary_fbeta_score</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Compute the F-beta score for binary classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    beta : float</span>
<span class="sd">        Weight of precision in harmonic mean.</span>
<span class="sd">    pos_label : int, default=1</span>
<span class="sd">        The positive class label. One of [0, 1].</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold value for converting probabilities and logits to binary.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there are no true positives or true negatives.</span>
<span class="sd">        If set to ``warn``, this acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The binary F-beta score.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        beta is less than 0.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import binary_fbeta_score</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0, 1, 1, 1]</span>
<span class="sd">    &gt;&gt;&gt; binary_fbeta_score(target, preds, beta=0.5)</span>
<span class="sd">    0.7142857142857143</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_beta</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
    <span class="n">_binary_stat_scores_args_check</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">)</span>

    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_binary_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_binary_stat_scores_update</span><span class="p">(</span>
        <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">_fbeta_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="multiclass_fbeta_score"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.f_beta.multiclass_fbeta_score.html#cyclops.evaluate.metrics.functional.f_beta.multiclass_fbeta_score">[docs]</a><span class="k">def</span> <span class="nf">multiclass_fbeta_score</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Compute the F-beta score for multiclass data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    beta : float</span>
<span class="sd">        Weight of precision in harmonic mean.</span>
<span class="sd">    num_classes : int</span>
<span class="sd">        The number of classes in the dataset.</span>
<span class="sd">    top_k : int, optional</span>
<span class="sd">        If given, and predictions are probabilities/logits, the score will</span>
<span class="sd">        be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">        set to 1.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the score for each class. Otherwise,</span>
<span class="sd">        use one of the following options to compute the average score:</span>

<span class="sd">        - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">            positives, false positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metric for each class, and find their</span>
<span class="sd">            unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metric for each class, and find their</span>
<span class="sd">            average weighted by the support (the number of true instances</span>
<span class="sd">            for each class). This alters &quot;macro&quot; to account for class imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or numpy.ndarray</span>
<span class="sd">        The multiclass F-beta score. If ``average`` is ``None``, a numpy array</span>
<span class="sd">        of shape (num_classes,) is returned.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        ``average`` is not one of ``micro``, ``macro``, ``weighted``, or ``None``,</span>
<span class="sd">        or ``beta`` is less than 0.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import multiclass_fbeta_score</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 2, 0]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0, 2, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; multiclass_fbeta_score(target, preds, beta=0.5, num_classes=3)</span>
<span class="sd">    array([1., 0., 0.])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_beta</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
    <span class="n">_check_average_arg</span><span class="p">(</span><span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">)</span>

    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_multiclass_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_multiclass_stat_scores_update</span><span class="p">(</span>
        <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">_fbeta_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="multilabel_fbeta_score"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.f_beta.multilabel_fbeta_score.html#cyclops.evaluate.metrics.functional.f_beta.multilabel_fbeta_score">[docs]</a><span class="k">def</span> <span class="nf">multilabel_fbeta_score</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the F-beta score for multilabel data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    beta : float</span>
<span class="sd">        Weight of precision in harmonic mean.</span>
<span class="sd">    num_labels : int</span>
<span class="sd">        Number of labels for the task.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for deciding the positive class.</span>
<span class="sd">    top_k : int, optional</span>
<span class="sd">        If given, and predictions are probabilities/logits, the score will</span>
<span class="sd">        be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">        set to 1.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the score for each label. Otherwise,</span>
<span class="sd">        use one of the following options to compute the average score:</span>

<span class="sd">        - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">            positives, false positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metric for each label, and find their</span>
<span class="sd">            unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metric for each label, and find their</span>
<span class="sd">            average weighted by the support (the number of true instances</span>
<span class="sd">            for each label). This alters &quot;macro&quot; to account for label</span>
<span class="sd">            imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or numpy.ndarray</span>
<span class="sd">        The multilabel F-beta score. If ``average`` is ``None``, a numpy array</span>
<span class="sd">        of shape (num_labels,) is returned.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        ``average`` is not one of ``micro``, ``macro``, ``weighted``, or ``None``,</span>
<span class="sd">        or ``beta`` is less than 0.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import multilabel_fbeta_score</span>
<span class="sd">    &gt;&gt;&gt; target = [[0, 1], [1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.1, 0.9], [0.8, 0.2]]</span>
<span class="sd">    &gt;&gt;&gt; multilabel_fbeta_score(target, preds, beta=0.5, num_labels=2)</span>
<span class="sd">    array([1.        , 0.83333333])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">_check_beta</span><span class="p">(</span><span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">)</span>
    <span class="n">_check_average_arg</span><span class="p">(</span><span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">)</span>

    <span class="n">target</span><span class="p">,</span> <span class="n">preds</span> <span class="o">=</span> <span class="n">_multilabel_stat_scores_format</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span> <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span> <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span>
    <span class="p">)</span>

    <span class="n">tp</span><span class="p">,</span> <span class="n">fp</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">fn</span> <span class="o">=</span> <span class="n">_multilabel_stat_scores_update</span><span class="p">(</span>
        <span class="n">target</span><span class="o">=</span><span class="n">target</span><span class="p">,</span> <span class="n">preds</span><span class="o">=</span><span class="n">preds</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">_fbeta_reduce</span><span class="p">(</span>
        <span class="n">tp</span><span class="o">=</span><span class="n">tp</span><span class="p">,</span>
        <span class="n">fp</span><span class="o">=</span><span class="n">fp</span><span class="p">,</span>
        <span class="n">fn</span><span class="o">=</span><span class="n">fn</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="n">beta</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="fbeta_score"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.f_beta.fbeta_score.html#cyclops.evaluate.metrics.functional.f_beta.fbeta_score">[docs]</a><span class="k">def</span> <span class="nf">fbeta_score</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">beta</span><span class="p">:</span> <span class="nb">float</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">],</span>
    <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Compute the F-beta score for binary, multiclass, or multilabel data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : ArrayLike</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>
<span class="sd">    beta : float</span>
<span class="sd">        Weight of precision in harmonic mean.</span>
<span class="sd">    task : Literal[&quot;binary&quot;, &quot;multiclass&quot;, &quot;multilabel&quot;]</span>
<span class="sd">        Type of classification task.</span>
<span class="sd">    pos_label : int, default=1</span>
<span class="sd">        Label to consider as positive for binary classification tasks.</span>
<span class="sd">    num_classes : int</span>
<span class="sd">        Number of classes for the task. Required if ``task`` is ``&quot;multiclass&quot;``.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for deciding the positive class. Only used if ``task`` is</span>
<span class="sd">        ``&quot;binary&quot;`` or ``&quot;multilabel&quot;``.</span>
<span class="sd">    top_k : int, optional</span>
<span class="sd">        If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">        be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">        set to 1. Only used if ``task`` is ``&quot;multiclass&quot;`` or ``&quot;multilabel&quot;``.</span>
<span class="sd">    num_labels : int</span>
<span class="sd">        Number of labels for the task. Required if ``task`` is ``&quot;multilabel&quot;``.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the score for each label/class. Otherwise,</span>
<span class="sd">        use one of the following options to compute the average score:</span>

<span class="sd">        - ``micro``: Calculate metrics globally by counting the total true</span>
<span class="sd">            positives, false positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metrics for each class/label, and find their</span>
<span class="sd">            unweighted mean. This does not take label/class imbalance into</span>
<span class="sd">            account.</span>
<span class="sd">        - ``weighted``: Calculate metrics for each label/class, and find</span>
<span class="sd">            their average weighted by support (the number of true instances</span>
<span class="sd">            for each label/class). This alters ``macro`` to account for</span>
<span class="sd">            label/class imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    score: float or numpy.ndarray</span>
<span class="sd">        The F-beta score. If ``average`` is not ``None`` and ``task`` is not</span>
<span class="sd">        ``binary``, a numpy array of shape (num_classes,) is returned.</span>

<span class="sd">    Raises</span>
<span class="sd">    ------</span>
<span class="sd">    ValueError</span>
<span class="sd">        If ``task`` is not one of ``binary``, ``multiclass``, or</span>
<span class="sd">        ``multilabel``.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    (binary)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import fbeta_score</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0.1, 0.8, 0.4, 0.3]</span>
<span class="sd">    &gt;&gt;&gt; fbeta_score(target, preds, beta=0.5, task=&quot;binary&quot;)</span>
<span class="sd">    0.8333333333333334</span>

<span class="sd">    (multiclass)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import fbeta_score</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 2, 2]</span>
<span class="sd">    &gt;&gt;&gt; preds = [1 2, 2, 0]</span>
<span class="sd">    &gt;&gt;&gt; fbeta_score(target, preds, beta=0.5, task=&quot;multiclass&quot;, num_classes=3)</span>
<span class="sd">    array([0.83333333, 0.        , 0.55555556])</span>

<span class="sd">    (multilabel)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import fbeta_score</span>
<span class="sd">    &gt;&gt;&gt; target = [[0, 1], [1, 1]]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.1, 0.9], [0.8, 0.2]]</span>
<span class="sd">    &gt;&gt;&gt; fbeta_score(target, preds, beta=0.5, task=&quot;multilabel&quot;, num_labels=2)</span>
<span class="sd">    array([1.        , 0.83333333])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;binary&quot;</span><span class="p">:</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">binary_fbeta_score</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">beta</span><span class="p">,</span>
            <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_classes</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_classes</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;Number of classes must be specified for multiclass classification.&quot;</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">multiclass_fbeta_score</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">beta</span><span class="p">,</span>
            <span class="n">num_classes</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>  <span class="c1"># type: ignore</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">elif</span> <span class="n">task</span> <span class="o">==</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">:</span>
        <span class="k">assert</span> <span class="p">(</span>
            <span class="nb">isinstance</span><span class="p">(</span><span class="n">num_labels</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="ow">and</span> <span class="n">num_labels</span> <span class="o">&gt;</span> <span class="mi">0</span>
        <span class="p">),</span> <span class="s2">&quot;Number of labels must be specified for multilabel classification.&quot;</span>
        <span class="n">score</span> <span class="o">=</span> <span class="n">multilabel_fbeta_score</span><span class="p">(</span>
            <span class="n">target</span><span class="p">,</span>
            <span class="n">preds</span><span class="p">,</span>
            <span class="n">beta</span><span class="p">,</span>
            <span class="n">num_labels</span><span class="p">,</span>
            <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
            <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
            <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
            <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;Task </span><span class="si">{</span><span class="n">task</span><span class="si">}</span><span class="s2"> is not supported, expected one of &#39;binary&#39;, &#39;multiclass&#39;&quot;</span>
            <span class="s2">&quot; or &#39;multilabel&#39;&quot;</span>
        <span class="p">)</span>

    <span class="k">return</span> <span class="n">score</span></div>


<div class="viewcode-block" id="binary_f1_score"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.f_beta.binary_f1_score.html#cyclops.evaluate.metrics.functional.f_beta.binary_f1_score">[docs]</a><span class="k">def</span> <span class="nf">binary_f1_score</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;Compute the F1 score for binary classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    pos_label: int, default=1</span>
<span class="sd">        The label of the positive class.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold value for binarizing predictions in form of logits or</span>
<span class="sd">        probability scores.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float</span>
<span class="sd">        The F1 score.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import binary_f1_score</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0.1, 0.8, 0.4, 0.3]</span>
<span class="sd">    &gt;&gt;&gt; binary_f1_score(target, preds)</span>
<span class="sd">    0.6666666666666666</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">binary_fbeta_score</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span>
        <span class="n">preds</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
        <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="multiclass_f1_score"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.f_beta.multiclass_f1_score.html#cyclops.evaluate.metrics.functional.f_beta.multiclass_f1_score">[docs]</a><span class="k">def</span> <span class="nf">multiclass_f1_score</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Compute the F1 score for multiclass classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    num_classes : int</span>
<span class="sd">        Number of classes in the dataset.</span>
<span class="sd">    top_k : int, optional</span>
<span class="sd">        If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">        be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">        set to 1.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the score for each class. Otherwise, use one of</span>
<span class="sd">        the following options to compute the average score:</span>

<span class="sd">        - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">            positives, false positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metric for each class, and find their</span>
<span class="sd">            unweighted mean. This does not take class imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metric for each class, and find their</span>
<span class="sd">            average weighted by the support (the number of true instances</span>
<span class="sd">            for each class). This alters &quot;macro&quot; to account for class</span>
<span class="sd">            imbalance. It can result in an F-score that is not between</span>
<span class="sd">            precision and recall.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or numpy.ndarray</span>
<span class="sd">        The F1 score. If ``average`` is ``None``, a numpy.ndarray of shape</span>
<span class="sd">        (``num_classes``,) is returned.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import multiclass_f1_score</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 2, 0]</span>
<span class="sd">    &gt;&gt;&gt; preds = [1, 1, 1, 0]</span>
<span class="sd">    &gt;&gt;&gt; multiclass_f1_score(target, preds, num_classes=3)</span>
<span class="sd">    array([0.66666667, 0.5       , 0.        ])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">multiclass_fbeta_score</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span>
        <span class="n">preds</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="multilabel_f1_score"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.f_beta.multilabel_f1_score.html#cyclops.evaluate.metrics.functional.f_beta.multilabel_f1_score">[docs]</a><span class="k">def</span> <span class="nf">multilabel_f1_score</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute the F1 score for multilabel classification tasks.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : ArrayLike</span>
<span class="sd">        Predictions as returned by a classifier.</span>
<span class="sd">    num_labels : int</span>
<span class="sd">        Number of labels for the task.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for deciding the positive class.</span>
<span class="sd">    top_k : int, optional</span>
<span class="sd">        If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">        be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">        set to 1.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the score for each label. Otherwise, use one of</span>
<span class="sd">        the following options to compute the average score:</span>

<span class="sd">        - ``micro``: Calculate metric globally from the total count of true</span>
<span class="sd">            positives, false positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metric for each label, and find their</span>
<span class="sd">            unweighted mean. This does not take label imbalance into account.</span>
<span class="sd">        - ``weighted``: Calculate metric for each label, and find their</span>
<span class="sd">            average weighted by the support (the number of true instances</span>
<span class="sd">            for each label). This alters &quot;macro&quot; to account for label imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or numpy.ndarray</span>
<span class="sd">        The F1 score. If ``average`` is ``None``, a numpy.ndarray of shape</span>
<span class="sd">        (``num_labels``,) is returned.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import multilabel_f1_score</span>
<span class="sd">    &gt;&gt;&gt; target = [[0, 1, 1], [1, 0, 0]]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.1, 0.9, 0.8], [0.05, 0.1, 0.2]]</span>
<span class="sd">    &gt;&gt;&gt; multilabel_f1_score(target, preds, num_labels=3)</span>
<span class="sd">    array([0., 1., 1.])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">multilabel_fbeta_score</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span>
        <span class="n">preds</span><span class="p">,</span>
        <span class="n">beta</span><span class="o">=</span><span class="mf">1.0</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
        <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>


<div class="viewcode-block" id="f1_score"><a class="viewcode-back" href="../../../../../reference/api/_autosummary/cyclops.evaluate.metrics.functional.f_beta.f1_score.html#cyclops.evaluate.metrics.functional.f_beta.f1_score">[docs]</a><span class="k">def</span> <span class="nf">f1_score</span><span class="p">(</span>  <span class="c1"># pylint: disable=too-many-arguments</span>
    <span class="n">target</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">preds</span><span class="p">:</span> <span class="n">ArrayLike</span><span class="p">,</span>
    <span class="n">task</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;binary&quot;</span><span class="p">,</span> <span class="s2">&quot;multiclass&quot;</span><span class="p">,</span> <span class="s2">&quot;multilabel&quot;</span><span class="p">],</span>
    <span class="n">pos_label</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">num_classes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">threshold</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span>
    <span class="n">top_k</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">average</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;micro&quot;</span><span class="p">,</span> <span class="s2">&quot;macro&quot;</span><span class="p">,</span> <span class="s2">&quot;weighted&quot;</span><span class="p">,</span> <span class="kc">None</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">zero_division</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;warn&quot;</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;warn&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
    <span class="sd">&quot;&quot;&quot;Compute the F1 score for multiclass data.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    target : ArrayLike</span>
<span class="sd">        Ground truth (correct) target values.</span>
<span class="sd">    preds : ArrayLike</span>
<span class="sd">        Estimated targets as returned by a classifier.</span>
<span class="sd">    task : Literal[&quot;binary&quot;, &quot;multiclass&quot;, &quot;multilabel&quot;]</span>
<span class="sd">        Type of classification task.</span>
<span class="sd">    pos_label : int, default=1</span>
<span class="sd">        Label to consider as positive for binary classification tasks.</span>
<span class="sd">    num_classes : int, default=None</span>
<span class="sd">        Number of classes for the task. Required if ``task`` is ``&quot;multiclass&quot;``.</span>
<span class="sd">    threshold : float, default=0.5</span>
<span class="sd">        Threshold for deciding the positive class. Only used if ``task`` is</span>
<span class="sd">        ``&quot;binary&quot;`` or ``&quot;multilabel&quot;``.</span>
<span class="sd">    top_k : int, optional</span>
<span class="sd">        If given, and predictions are probabilities/logits, the precision will</span>
<span class="sd">        be computed only for the top k classes. Otherwise, ``top_k`` will be</span>
<span class="sd">        set to 1. Only used if ``task`` is ``&quot;multiclass&quot;`` or ``&quot;multilabel&quot;``.</span>
<span class="sd">    num_labels : int, default=None</span>
<span class="sd">        Number of labels for the task. Required if ``task`` is ``&quot;multilabel&quot;``.</span>
<span class="sd">    average : Literal[&quot;micro&quot;, &quot;macro&quot;, &quot;weighted&quot;, None], default=None</span>
<span class="sd">        If ``None``, return the score for each label/class. Otherwise,</span>
<span class="sd">        use one of the following options to compute the average score:</span>

<span class="sd">        - ``micro``: Calculate metrics globally by counting the total true</span>
<span class="sd">            positives, false positives and false negatives.</span>
<span class="sd">        - ``macro``: Calculate metrics for each class/label, and find their</span>
<span class="sd">            unweighted mean. This does not take label/class imbalance into</span>
<span class="sd">            account.</span>
<span class="sd">        - ``weighted``: Calculate metrics for each label/class, and find</span>
<span class="sd">            their average weighted by support (the number of true instances</span>
<span class="sd">            for each label/class). This alters ``macro`` to account for</span>
<span class="sd">            label/class imbalance.</span>
<span class="sd">    zero_division : Literal[&quot;warn&quot;, 0, 1], default=&quot;warn&quot;</span>
<span class="sd">        Value to return when there is a zero division. If set to &quot;warn&quot;, this</span>
<span class="sd">        acts as 0, but warnings are also raised.</span>


<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    float or numpy.ndarray</span>
<span class="sd">        The F1 score. If ``average`` is ``None`` and ``task`` is not ``binary``,</span>
<span class="sd">        a numpy.ndarray of shape (``num_classes`` or ``num_labels``,) is returned.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    &gt;&gt;&gt; # (binary)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import f1_score</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 0, 1]</span>
<span class="sd">    &gt;&gt;&gt; preds = [0.1, 0.9, 0.8, 0.2]</span>
<span class="sd">    &gt;&gt;&gt; f1_score(target, preds, task=&quot;binary&quot;)</span>
<span class="sd">    0.5</span>

<span class="sd">    &gt;&gt;&gt; # (multiclass)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import f1_score</span>
<span class="sd">    &gt;&gt;&gt; target = [0, 1, 2, 0]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.05, 0.95, 0], [0.1, 0.8, 0.1], [0.2, 0.2, 0.6], [0.9, 0.1, 0]]</span>
<span class="sd">    &gt;&gt;&gt; f1_score(target, preds, task=&quot;multiclass&quot;, num_classes=3)</span>
<span class="sd">    array([0.66666667, 0.8       , 0.        ])</span>

<span class="sd">    &gt;&gt;&gt; # (multilabel)</span>
<span class="sd">    &gt;&gt;&gt; from cyclops.evaluation.metrics.functional import f1_score</span>
<span class="sd">    &gt;&gt;&gt; target = [[0, 1, 1], [1, 0, 0]]</span>
<span class="sd">    &gt;&gt;&gt; preds = [[0.1, 0.9, 0.8], [0.05, 0.1, 0.2]]</span>
<span class="sd">    &gt;&gt;&gt; f1_score(target, preds, task=&quot;multilabel&quot;, num_labels=3)</span>
<span class="sd">    array([0., 1., 1.])</span>

<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">fbeta_score</span><span class="p">(</span>
        <span class="n">target</span><span class="p">,</span>
        <span class="n">preds</span><span class="p">,</span>
        <span class="mf">1.0</span><span class="p">,</span>
        <span class="n">task</span><span class="p">,</span>
        <span class="n">pos_label</span><span class="o">=</span><span class="n">pos_label</span><span class="p">,</span>
        <span class="n">num_classes</span><span class="o">=</span><span class="n">num_classes</span><span class="p">,</span>
        <span class="n">threshold</span><span class="o">=</span><span class="n">threshold</span><span class="p">,</span>
        <span class="n">top_k</span><span class="o">=</span><span class="n">top_k</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span><span class="p">,</span>
        <span class="n">average</span><span class="o">=</span><span class="n">average</span><span class="p">,</span>
        <span class="n">zero_division</span><span class="o">=</span><span class="n">zero_division</span><span class="p">,</span>
    <span class="p">)</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p></p>
  </div>

  

  <div class="citation">
    CyclOps team <i>et al.,</i>
    <a href="https://www.medrxiv.org/content/10.1101/2022.12.02.22283021v2">CyclOps: Cyclical development towards Operationalizing ML models for health</a>
    <i>, medarxiv</i> (2022)
  </def>


  <p class="avatar">cyclops is built by</p>
  <div class="avatar">
    
    
    <span>
      <a href="https://github.com/amrit110">
        <img src="../../../../../_static/team/amrit-krishnan.jpg" width="32"/>
        Amrit Krishnan
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/KadenMc">
        <img src="../../../../../_static/team/kaden-mckeen.jpg" width="32"/>
        Kaden McKeen
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/vsubasri">
        <img src="../../../../../_static/team/valli-subasri.jpg" width="32"/>
        Valli Subasri
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/a-kore">
        <img src="../../../../../_static/team/ali-kore.jpg" width="32"/>
        Ali Kore
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/fcogidi">
        <img src="../../../../../_static/team/franklin-ogidi.jpg" width="32"/>
        Franklin Ogidi
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/mahshidaln">
        <img src="../../../../../_static/team/mahshid-alinoori.jpg" width="32"/>
        Mahshid Alinoori
      </a>
    </span>
    ,
    
    <span>
      <a href="https://github.com/elhamdolatabadi">
        <img src="../../../../../_static/team/elham-dolatabadi.jpg" width="32"/>
        Elham Dolatabadi
      </a>
    </span>
    ,
  </div>


  <div class="footer-small-text">
    All <a href="https://github.com/VectorInstitute/cyclops">source code for cyclops</a> is freely available under the terms of an <a href="https://opensource.org/licenses/Apache-2.0">Apache-2.0</a> license.
  </div>

  <div class="footer-small-text">
    This work is made possible due to the data obtained from the
    General Medicine Inpatient Initiative (GEMINI).
  </div>

  <hr/>

  <div class="logo">
    <a class="logo" href="https://vectorinstitute.ai/">
      <span class="logo"></span>
      <img alt="Logo of the Vector Institute" style="width:90px; max-width:90px;" src="../../../../../_static/logos/vector_logo.png" />
    </a>
    <a class="logo" href="https://www.geminimedicine.ca/">
      <span class="logo"></span>
      <img alt="Logo of GEMINI" style="width:90px; max-width:90px;" src="../../../../../_static/logos/gemini_logo.png" />
    </a>
  </div>

  <div class="copyright">
    &copy; Copyright 2022, Vector AI Engineering
  </div>

  <div class="copyright">
    </p>
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using customised version of
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">base theme</a> provided by
    <a href="https://readthedocs.org">Read the Docs</a>.
  </div>



</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>